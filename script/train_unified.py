#!/usr/bin/env python3
"""
ç»Ÿä¸€è®­ç»ƒè„šæœ¬ - æ”¯æŒå¤šæ¨¡å‹ã€è‡ªå®šä¹‰epochså’Œçµæ´»æ•°æ®é›†é…ç½®
æ”¯æŒä»checkpointæ¢å¤è®­ç»ƒ
"""

import os
import sys
import importlib.util
import gc
import json
import torch
import argparse
import logging
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from dataset_simple import SimplePhoneImageDataset
from model import get_model
# ç¡®ä¿ä¼˜å…ˆä»å½“å‰è„šæœ¬ç›®å½•å¯¼å…¥åŒåæ¨¡å—ï¼ˆé¿å…è¢«å¤–éƒ¨ä¾èµ–é®è”½ï¼‰
CURRENT_DIR = os.path.abspath(os.path.dirname(__file__))
if CURRENT_DIR not in sys.path:
    sys.path.insert(0, CURRENT_DIR)

# åŠ¨æ€åŠ è½½æœ¬åœ° trainer.pyï¼Œé¿å…è¢«å…¶ä»–åŒåæ¨¡å—é®è”½
_local_trainer_path = os.path.join(CURRENT_DIR, 'trainer.py')
_spec_trainer = importlib.util.spec_from_file_location('local_trainer', _local_trainer_path)
if _spec_trainer is None or _spec_trainer.loader is None:
    raise ImportError(f"æ— æ³•åŠ è½½æœ¬åœ°è®­ç»ƒå™¨: {_local_trainer_path}")
_local_trainer_mod = importlib.util.module_from_spec(_spec_trainer)
_spec_trainer.loader.exec_module(_local_trainer_mod)
Trainer = _local_trainer_mod.Trainer
from torchvision import transforms
from torch.utils import data
from torch.utils.data import WeightedRandomSampler

# é…ç½®æ—¥å¿—
def setup_logging(log_dir: str = "logs"):
    """è®¾ç½®æ—¥å¿—"""
    os.makedirs(log_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = f"{log_dir}/unified_training_{timestamp}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

class UnifiedTrainer:
    """ç»Ÿä¸€è®­ç»ƒå™¨"""
    
    def __init__(self, logger, device='auto'):
        self.logger = logger
        
        # è®¾ç½®è®¾å¤‡
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        self.logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        if torch.cuda.is_available():
            self.logger.info(f"GPUæ•°é‡: {torch.cuda.device_count()}")
            self.logger.info(f"å½“å‰GPU: {torch.cuda.get_device_name()}")
        
        self.num_workers = min(4, os.cpu_count())
        
        # é¢„å®šä¹‰æ¨¡å‹é…ç½® - æ ¹æ®è®¾å¤‡ä¼˜åŒ–batch_size
        if torch.cuda.is_available():
            self.model_configs = {
                # åŸæœ‰æ¨¡å‹
                'resnet152': {
                    'batch_size': 16,  # GPUæ—¶å¢å¤§batch_size
                    'accumulation_steps': 2,
                    'lr': 0.001,
                    'description': 'ResNet152 CNNæ¨¡å‹'
                },
                'vit_base': {
                    'batch_size': 12,
                    'accumulation_steps': 2,
                    'lr': 0.0001,
                    'description': 'ViT-Base Transformeræ¨¡å‹'
                },
                'vit_base_multicls': {
                    'batch_size': 12,
                    'accumulation_steps': 2,
                    'lr': 0.0001,
                    'description': 'ViT-Base å¤šCLS Tokenæ¨¡å‹'
                },
                'vit_large': {
                    'batch_size': 8,
                    'accumulation_steps': 3,
                    'lr': 0.0001,
                    'description': 'ViT-Large Transformeræ¨¡å‹'
                },
                # æ–°å¢6ç§ç½‘ç»œçš„æœ€å¤§å‚æ•°ç‰ˆæœ¬
                'densenet161': {
                    'batch_size': 10,
                    'accumulation_steps': 3,
                    'lr': 0.0005,
                    'description': 'DenseNet-161 (29Må‚æ•°)'
                },
                'mobilenet_v3_large': {
                    'batch_size': 24,
                    'accumulation_steps': 1,
                    'lr': 0.001,
                    'description': 'MobileNet-V3-Large (5.4Må‚æ•°)'
                },
                'resnext101_64x4d': {
                    'batch_size': 6,
                    'accumulation_steps': 4,
                    'lr': 0.0005,
                    'description': 'ResNeXt-101-64x4d (84Må‚æ•°)'
                },
                'swin_base_patch4_window7_224': {
                    'batch_size': 8,
                    'accumulation_steps': 3,
                    'lr': 0.0001,
                    'description': 'Swin-Base (88Må‚æ•°)'
                },
                'convnext_base': {
                    'batch_size': 8,
                    'accumulation_steps': 3,
                    'lr': 0.0001,
                    'description': 'ConvNeXt-Base (89Må‚æ•°)'
                },
                'efficientnet_b7': {
                    'batch_size': 4,
                    'accumulation_steps': 6,
                    'lr': 0.0001,
                    'description': 'EfficientNet-B7 (66Må‚æ•°)'
                },
                'efficientnet_v2_s': {
                    'batch_size': 16,
                    'accumulation_steps': 2,
                    'lr': 0.0005,
                    'description': 'EfficientNetV2-S (24Må‚æ•°)',
                    'input_size': 256
                },
                'efficientnet_v2_lite0': {
                    'batch_size': 24,
                    'accumulation_steps': 1,
                    'lr': 0.001,
                    'description': 'EfficientNetV2-T (13Må‚æ•°)',
                    'input_size': 224
                }
            }
        else:
            self.model_configs = {
                # åŸæœ‰æ¨¡å‹
                'resnet152': {
                    'batch_size': 8,
                    'accumulation_steps': 3,
                    'lr': 0.001,
                    'description': 'ResNet152 CNNæ¨¡å‹'
                },
                'vit_base': {
                    'batch_size': 6,
                    'accumulation_steps': 4,
                    'lr': 0.0001,
                    'description': 'ViT-Base Transformeræ¨¡å‹'
                },
                'vit_base_multicls': {
                    'batch_size': 6,
                    'accumulation_steps': 4,
                    'lr': 0.0001,
                    'description': 'ViT-Base å¤šCLS Tokenæ¨¡å‹'
                },
                'vit_large': {
                    'batch_size': 4,
                    'accumulation_steps': 6,
                    'lr': 0.0001,
                    'description': 'ViT-Large Transformeræ¨¡å‹'
                },
                # æ–°å¢6ç§ç½‘ç»œçš„æœ€å¤§å‚æ•°ç‰ˆæœ¬ (CPUé…ç½®æ›´ä¿å®ˆ)
                'densenet161': {
                    'batch_size': 4,
                    'accumulation_steps': 6,
                    'lr': 0.0005,
                    'description': 'DenseNet-161 (29Må‚æ•°)'
                },
                'mobilenet_v3_large': {
                    'batch_size': 12,
                    'accumulation_steps': 2,
                    'lr': 0.001,
                    'description': 'MobileNet-V3-Large (5.4Må‚æ•°)'
                },
                'resnext101_64x4d': {
                    'batch_size': 2,
                    'accumulation_steps': 12,
                    'lr': 0.0005,
                    'description': 'ResNeXt-101-64x4d (84Må‚æ•°)'
                },
                'swin_base_patch4_window7_224': {
                    'batch_size': 3,
                    'accumulation_steps': 8,
                    'lr': 0.0001,
                    'description': 'Swin-Base (88Må‚æ•°)'
                },
                'convnext_base': {
                    'batch_size': 3,
                    'accumulation_steps': 8,
                    'lr': 0.0001,
                    'description': 'ConvNeXt-Base (89Må‚æ•°)'
                },
                'efficientnet_b7': {
                    'batch_size': 2,
                    'accumulation_steps': 12,
                    'lr': 0.0001,
                    'description': 'EfficientNet-B7 (66Må‚æ•°)'
                },
                'efficientnet_v2_s': {
                    'batch_size': 10,
                    'accumulation_steps': 3,
                    'lr': 0.0005,
                    'description': 'EfficientNetV2-S (24Må‚æ•°)',
                    'input_size': 256
                },
                'efficientnet_v2_lite0': {
                    'batch_size': 16,
                    'accumulation_steps': 2,
                    'lr': 0.001,
                    'description': 'EfficientNetV2-T (13Må‚æ•°)',
                    'input_size': 224
                }
            }
    
    def validate_data_paths(self, data_config: Dict) -> bool:
        """éªŒè¯æ•°æ®è·¯å¾„"""
        for key, paths in data_config.items():
            if isinstance(paths, str):
                paths = [paths]
            for path in paths:
                if not os.path.exists(path):
                    self.logger.error(f"æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {path}")
                    return False
                if not os.listdir(path):
                    self.logger.error(f"æ•°æ®æ–‡ä»¶å¤¹ä¸ºç©º: {path}")
                    return False
        return True
    
    def load_checkpoint(self, checkpoint_path: str) -> Optional[Dict]:
        """åŠ è½½checkpoint"""
        try:
            if os.path.exists(checkpoint_path):
                self.logger.info(f"ğŸ”„ ä»checkpointæ¢å¤: {checkpoint_path}")
                checkpoint = torch.load(checkpoint_path, map_location=self.device)
                return checkpoint
            else:
                self.logger.warning(f"Checkpointæ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
                return None
        except Exception as e:
            self.logger.error(f"åŠ è½½checkpointå¤±è´¥: {str(e)}")
            return None
    
    def load_dataset(self, data_config: Dict, validation_split: float = 0.2,
                     input_size: int = 224, val_max_samples: int = 0) -> Tuple[data.DataLoader, data.DataLoader]:
        """åŠ è½½æ•°æ®é›†"""
        self.logger.info("ğŸ“‚ å¼€å§‹åŠ è½½æ•°æ®é›†")
        
        # æ•°æ®å¢å¼º
        transform = transforms.Compose([
            transforms.Resize((input_size, input_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # æ„å»ºæ•°æ®é›†å‚æ•°
        if 'raw' in data_config and 'recap' in data_config:
            # æ ‡å‡†æ¨¡å¼ï¼šrawå’Œrecapæ–‡ä»¶å¤¹
            raw_paths = data_config['raw'] if isinstance(data_config['raw'], list) else [data_config['raw']]
            recap_paths = data_config['recap'] if isinstance(data_config['recap'], list) else [data_config['recap']]
            
            dataset = SimplePhoneImageDataset(
                raw_folder_paths=raw_paths,
                recap_folder_paths=recap_paths,
                transform=transform
            )
        elif 'positive' in data_config and 'negative' in data_config:
            # é€šç”¨æ¨¡å¼ï¼špositiveå’Œnegativeæ–‡ä»¶å¤¹
            pos_paths = data_config['positive'] if isinstance(data_config['positive'], list) else [data_config['positive']]
            neg_paths = data_config['negative'] if isinstance(data_config['negative'], list) else [data_config['negative']]
            
            # è¿™é‡Œå°†positiveæ˜ å°„ä¸ºrecapï¼Œnegativeæ˜ å°„ä¸ºraw
            dataset = SimplePhoneImageDataset(
                raw_folder_paths=neg_paths,
                recap_folder_paths=pos_paths,
                transform=transform
            )
        else:
            raise ValueError("æ•°æ®é…ç½®å¿…é¡»åŒ…å« 'raw'+'recap' æˆ– 'positive'+'negative'")
        
        # ç»Ÿè®¡æ•°æ®
        self.logger.info(f"æ•°æ®åŠ è½½å®Œæˆ: {len(dataset)} å¼ å›¾ç‰‡")
        
        # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
        dataset_size = len(dataset)
        train_size = int(dataset_size * (1 - validation_split))
        val_size = dataset_size - train_size
        
        train_dataset, val_dataset = data.random_split(dataset, [train_size, val_size])

        # å¯é€‰åœ°è£å‰ªéªŒè¯é›†è§„æ¨¡ä»¥ç¼©çŸ­éªŒè¯æ—¶é—´
        effective_val_size = len(val_dataset)
        if val_max_samples > 0 and effective_val_size > val_max_samples:
            generator = torch.Generator()
            generator.manual_seed(42)
            selection = torch.randperm(effective_val_size, generator=generator)[:val_max_samples].tolist()
            selected_indices = [val_dataset.indices[idx] for idx in selection]
            val_dataset = data.Subset(val_dataset.dataset, selected_indices)
            self.logger.info(f"ğŸ” éªŒè¯é›†è£å‰ª: åŸå§‹ {effective_val_size} å¼  -> ä½¿ç”¨ {len(val_dataset)} å¼ ")
            effective_val_size = len(val_dataset)
        
        self.logger.info(f"ğŸ“Š æ•°æ®é›†åˆ†å‰²:")
        self.logger.info(f"  æ€»æ•°æ®é‡: {dataset_size} å¼ ")
        self.logger.info(f"  è®­ç»ƒé›†: {len(train_dataset)} å¼ ")
        self.logger.info(f"  éªŒè¯é›†: {effective_val_size} å¼ ")
        
        return train_dataset, val_dataset
    
    def _build_recap_sampler(self, subset, oversample_factor: float) -> Optional[WeightedRandomSampler]:
        """ä¸ºRecapä¼˜å…ˆç­–ç•¥åˆ›å»ºé‡‡æ ·å™¨"""
        if oversample_factor <= 1.0:
            return None
        if not hasattr(subset, 'indices') or not hasattr(subset, 'dataset'):
            return None
        indices = subset.indices
        labels = subset.dataset.labels
        sample_labels = [labels[idx] for idx in indices]
        positive_label = 1
        recap_count = sum(1 for label in sample_labels if label == positive_label)
        raw_count = len(sample_labels) - recap_count
        if recap_count == 0 or raw_count == 0:
            self.logger.warning("âš ï¸ Recapä¼˜å…ˆé‡‡æ ·æœªå¯ç”¨ï¼šè®­ç»ƒå­é›†ä¸­ç¼ºå°‘æŸä¸ªç±»åˆ«")
            return None
        total = len(sample_labels)
        pos_weight = oversample_factor * (total / (2 * recap_count))
        neg_weight = total / (2 * raw_count)
        weights = [pos_weight if label == positive_label else neg_weight for label in sample_labels]
        self.logger.info(f"ğŸ¯ Recapä¼˜å…ˆé‡‡æ ·å¯ç”¨ (raw={raw_count}, recap={recap_count}, oversample={oversample_factor})")
        return WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)
    
    def create_data_loaders(self, train_dataset, val_dataset, batch_size: int,
                             recap_priority: bool = False, recap_oversample: float = 1.0) -> Tuple[data.DataLoader, data.DataLoader]:
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        sampler = self._build_recap_sampler(train_dataset, recap_oversample) if recap_priority else None
        train_loader = data.DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=(sampler is None),
            sampler=sampler,
            num_workers=self.num_workers,
            pin_memory=False,
            drop_last=True  # é¿å…BNåœ¨æœ€åä¸€ä¸ªbatchä¸º1æ—¶æŠ¥é”™
        )
        
        val_loader = data.DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=self.num_workers,
            pin_memory=False
        )
        
        return train_loader, val_loader
    
    def train_single_model(self, model_name: str, epochs: int, data_config: Dict, 
                          validation_split: float = 0.2, save_dir: str = "checkpoints",
                          resume_from: Optional[str] = None, use_focal_loss: bool = True,
                          focal_alpha: float = 0.65, focal_gamma: float = 2.0,
                          primary_metric: str = 'accuracy', recap_priority: bool = False,
                          recap_oversample: float = 1.0, use_pretrained: bool = True,
                          val_max_samples: int = 0, raw_loss_weight: float = 1.0,
                          recap_loss_weight: float = 1.0,
                          focal_alpha_neg: Optional[float] = None,
                          focal_alpha_pos: Optional[float] = None) -> bool:
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        try:
            self.logger.info("="*60)
            self.logger.info(f"å¼€å§‹è®­ç»ƒ {model_name.upper()}")
            self.logger.info("="*60)
            
            # è·å–æ¨¡å‹é…ç½®
            if model_name not in self.model_configs:
                self.logger.error(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
                return False
            
            config = self.model_configs[model_name].copy()
            config['epochs'] = epochs
            
            self.logger.info(f"ğŸ¤– æ¨¡å‹: {config['description']}")
            self.logger.info(f"ğŸ“Š Epochs: {epochs}")
            self.logger.info(f"ğŸ’¾ æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
            self.logger.info(f"ğŸ“ˆ å­¦ä¹ ç‡: {config['lr']}")
            
            # ç¡®å®šè¾“å…¥å°ºå¯¸
            input_size = config.get('input_size', 224)
            
            # å‡†å¤‡æŸå¤±æƒé‡
            class_loss_weights = None
            if raw_loss_weight != 1.0 or recap_loss_weight != 1.0:
                class_loss_weights = (raw_loss_weight, recap_loss_weight)
                self.logger.info(f"âš–ï¸ è‡ªå®šä¹‰ç±»åˆ«æŸå¤±æƒé‡: raw={raw_loss_weight}, recap={recap_loss_weight}")

            # å¤„ç†Focal Lossçš„Î±è®¾ç½®
            focal_alpha_value = focal_alpha
            if focal_alpha_neg is not None or focal_alpha_pos is not None:
                if focal_alpha_neg is None or focal_alpha_pos is None:
                    self.logger.error("âŒ åŒæ—¶æŒ‡å®š --focal-alpha-neg å’Œ --focal-alpha-pos æ‰èƒ½ç”Ÿæ•ˆ")
                    return False
                focal_alpha_value = (focal_alpha_neg, focal_alpha_pos)
                self.logger.info(f"ğŸ¯ è‡ªå®šä¹‰Focal Î±: neg={focal_alpha_neg}, pos={focal_alpha_pos}")

            # åŠ è½½æ•°æ®é›†
            train_dataset, val_dataset = self.load_dataset(
                data_config,
                validation_split,
                input_size=input_size,
                val_max_samples=val_max_samples
            )
            train_loader, val_loader = self.create_data_loaders(
                train_dataset, val_dataset, config['batch_size'],
                recap_priority=recap_priority,
                recap_oversample=recap_oversample
            )
            
            # åˆ›å»ºæ¨¡å‹
            if not use_pretrained:
                self.logger.info("ğŸŒ é¢„è®­ç»ƒæƒé‡å·²ç¦ç”¨ï¼Œå°†ä»éšæœºåˆå§‹åŒ–å¼€å§‹è®­ç»ƒ")
            model = get_model(model_name, num_classes=2, pretrained=use_pretrained)
            model = model.to(self.device)
            
            # å°è¯•åŠ è½½checkpoint
            checkpoint = None
            start_epoch = 0
            best_val_acc = 0.0
            model_save_dir = None
            
            if resume_from:
                checkpoint = self.load_checkpoint(resume_from)
                if checkpoint:
                    # åŠ è½½æ¨¡å‹æƒé‡
                    if 'model_state_dict' in checkpoint:
                        model.load_state_dict(checkpoint['model_state_dict'])
                        self.logger.info("âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡")
                    
                    # è·å–è®­ç»ƒçŠ¶æ€
                    start_epoch = checkpoint.get('epoch', 0)
                    best_val_acc = checkpoint.get('best_val_acc', 0.0)
                    
                    # ä½¿ç”¨åŸæœ‰çš„ä¿å­˜ç›®å½•
                    checkpoint_dir = os.path.dirname(resume_from)
                    model_save_dir = checkpoint_dir
                    
                    self.logger.info(f"ğŸ”„ ä»epoch {start_epoch} å¼€å§‹ç»§ç»­è®­ç»ƒ")
                    self.logger.info(f"ğŸ“Š å½“å‰æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
                else:
                    self.logger.warning("âš ï¸ CheckpointåŠ è½½å¤±è´¥ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")
            
            # å¦‚æœæ²¡æœ‰ä»checkpointæ¢å¤ï¼Œåˆ›å»ºæ–°çš„ä¿å­˜ç›®å½•
            if model_save_dir is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                model_save_dir = f"{save_dir}/{model_name}_{timestamp}_unified"
                os.makedirs(model_save_dir, exist_ok=True)
            
            self.logger.info(f"ğŸ’¾ æ¨¡å‹checkpointså°†ä¿å­˜åˆ°: {model_save_dir}")
            
            # ä¿å­˜è®­ç»ƒé…ç½®
            training_config = {
                'model_name': model_name,
                'epochs': epochs,
                'batch_size': config['batch_size'],
                'learning_rate': config['lr'],
                'accumulation_steps': config['accumulation_steps'],
                'data_config': data_config,
                'validation_split': validation_split,
                'device': str(self.device),
                'timestamp': datetime.now().strftime("%Y%m%d_%H%M%S"),
                'dataset_size': len(train_dataset) + len(val_dataset),
                'train_size': len(train_dataset),
                'val_size': len(val_dataset),
                'resume_from': resume_from,
                'start_epoch': start_epoch,
                'primary_metric': primary_metric,
                'focal_alpha': focal_alpha_value,
                'focal_gamma': focal_gamma,
                'class_loss_weights': class_loss_weights,
                'recap_priority': recap_priority,
                'recap_oversample': recap_oversample
            }
            
            config_path = os.path.join(model_save_dir, "training_config.json")
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(training_config, f, indent=2, ensure_ascii=False)
            
            # åˆ›å»ºè®­ç»ƒå™¨ - ä½¿ç”¨Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡
            trainer = Trainer(
                model=model,
                train_loader=train_loader,
                val_loader=val_loader,
                device=self.device,
                lr=config['lr'],
                accumulation_steps=config['accumulation_steps'],
                save_dir=model_save_dir,
                warmup_epochs=1,  # è®¾ç½®é¢„çƒ­è½®æ•°ä¸º1
                use_focal_loss=use_focal_loss,  # å¯ç”¨Focal Loss
                focal_alpha=focal_alpha_value,  # è‡ªå®šä¹‰Î±
                focal_gamma=focal_gamma,   # èšç„¦å‚æ•°
                primary_metric=primary_metric,
                positive_label=1,
                class_loss_weights=class_loss_weights
            )
            
            # å¦‚æœä»checkpointæ¢å¤ï¼Œè®¾ç½®è®­ç»ƒå™¨çŠ¶æ€
            if checkpoint:
                trainer.set_resume_state(checkpoint, start_epoch, best_val_acc, override_primary_metric=primary_metric)
            
            # å¼€å§‹è®­ç»ƒï¼ˆè®¡ç®—å‰©ä½™çš„epochsï¼‰
            remaining_epochs = epochs - start_epoch
            if remaining_epochs > 0:
                self.logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒå‰©ä½™çš„ {remaining_epochs} ä¸ªepochs")
                trainer.train(remaining_epochs)
            else:
                self.logger.info("âœ… å·²è¾¾åˆ°ç›®æ ‡epochsï¼Œæ— éœ€ç»§ç»­è®­ç»ƒ")
            
            self.logger.info(f"âœ… {model_name} è®­ç»ƒå®Œæˆ")
            
            # æ¸…ç†å†…å­˜
            del model, trainer, train_loader, val_loader
            torch.cuda.empty_cache() if torch.cuda.is_available() else None
            gc.collect()
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ è®­ç»ƒ {model_name} å¤±è´¥: {str(e)}")
            return False
    
    def train_multiple_models(self, training_plan: List[Dict], data_config: Dict,
                            validation_split: float = 0.2, save_dir: str = "checkpoints",
                            resume_from: Optional[str] = None, use_focal_loss: bool = True,
                            focal_alpha: float = 0.65, focal_gamma: float = 2.0,
                            primary_metric: str = 'accuracy', recap_priority: bool = False,
                            recap_oversample: float = 1.0, use_pretrained: bool = True,
                            val_max_samples: int = 0, raw_loss_weight: float = 1.0,
                            recap_loss_weight: float = 1.0,
                            focal_alpha_neg: Optional[float] = None,
                            focal_alpha_pos: Optional[float] = None):
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        self.logger.info("ğŸš€ å¼€å§‹å¤šæ¨¡å‹è®­ç»ƒ")
        self.logger.info("="*80)
        self.logger.info(f"ğŸ“‚ æ•°æ®é…ç½®: {data_config}")
        self.logger.info(f"ğŸ”§ CPUçº¿ç¨‹æ•°: {self.num_workers}")
        self.logger.info(f"ğŸ“Š éªŒè¯é›†æ¯”ä¾‹: {validation_split*100:.1f}%")
        if resume_from:
            self.logger.info(f"ğŸ”„ ä»checkpointæ¢å¤: {resume_from}")
        self.logger.info("="*80)

        if not use_pretrained:
            self.logger.info("ğŸŒ æœ¬æ¬¡è®­ç»ƒè·³è¿‡é¢„è®­ç»ƒæƒé‡åŠ è½½ï¼ˆä¸ä¼šè®¿é—®å¤–éƒ¨ç½‘ç»œï¼‰")
        if val_max_samples > 0:
            self.logger.info(f"âš¡ éªŒè¯é›†å°†æœ€å¤šé‡‡æ · {val_max_samples} å¼ å›¾ç‰‡ä»¥åŠ é€Ÿè¯„ä¼°")
        if (focal_alpha_neg is None) != (focal_alpha_pos is None):
            self.logger.error("âŒ è¯·åŒæ—¶æŒ‡å®š --focal-alpha-neg å’Œ --focal-alpha-pos")
            return
        if raw_loss_weight != 1.0 or recap_loss_weight != 1.0:
            self.logger.info(f"âš–ï¸ å…¨å±€æŸå¤±æƒé‡: raw={raw_loss_weight}, recap={recap_loss_weight}")
        if focal_alpha_neg is not None and focal_alpha_pos is not None:
            self.logger.info(f"ğŸ¯ å…¨å±€Focal Î±è®¾å®š: neg={focal_alpha_neg}, pos={focal_alpha_pos}")
        
        # éªŒè¯æ•°æ®è·¯å¾„
        if not self.validate_data_paths(data_config):
            self.logger.error("âŒ æ•°æ®è·¯å¾„éªŒè¯å¤±è´¥")
            return
        
        results = []
        successful_models = 0
        total_models = len(training_plan)
        
        for i, plan in enumerate(training_plan, 1):
            model_name = plan['model']
            epochs = plan['epochs']
            
            self.logger.info(f"\nğŸ”„ è¿›åº¦: {i}/{total_models} - è®­ç»ƒ {model_name} ({epochs} epochs)")
            
            success = self.train_single_model(
                model_name=model_name,
                epochs=epochs,
                data_config=data_config,
                validation_split=validation_split,
                save_dir=save_dir,
                resume_from=resume_from if i == 1 else None,  # åªå¯¹ç¬¬ä¸€ä¸ªæ¨¡å‹ä½¿ç”¨resume
                use_focal_loss=use_focal_loss,
                focal_alpha=focal_alpha,
                focal_gamma=focal_gamma,
                primary_metric=primary_metric,
                recap_priority=recap_priority,
                recap_oversample=recap_oversample,
                use_pretrained=use_pretrained,
                val_max_samples=val_max_samples,
                raw_loss_weight=raw_loss_weight,
                recap_loss_weight=recap_loss_weight,
                focal_alpha_neg=focal_alpha_neg,
                focal_alpha_pos=focal_alpha_pos
            )
            
            results.append({
                'model': model_name,
                'epochs': epochs,
                'success': success
            })
            
            if success:
                successful_models += 1
        
        # è¾“å‡ºæœ€ç»ˆç»“æœ
        self.logger.info("\n" + "="*80)
        self.logger.info("ğŸ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ")
        self.logger.info("="*80)
        self.logger.info(f"âœ… æˆåŠŸè®­ç»ƒ: {successful_models}/{total_models} ä¸ªæ¨¡å‹")
        
        if successful_models > 0:
            self.logger.info("\nğŸ“Š æˆåŠŸè®­ç»ƒçš„æ¨¡å‹:")
            for result in results:
                if result['success']:
                    self.logger.info(f"  âœ… {result['model']} - {result['epochs']} epochs")
        
        if successful_models < total_models:
            self.logger.info("\nâŒ å¤±è´¥çš„æ¨¡å‹:")
            for result in results:
                if not result['success']:
                    self.logger.info(f"  âŒ {result['model']} - {result['epochs']} epochs")

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€è®­ç»ƒè„šæœ¬ - æ”¯æŒæ–­ç‚¹ç»­è®­')
    
    # è®¾å¤‡é€‰æ‹©
    parser.add_argument('--device', choices=['auto', 'cpu', 'cuda'], default='auto',
                       help='è®¾å¤‡é€‰æ‹© (é»˜è®¤: auto)')
    
    # è®­ç»ƒè®¡åˆ’
    parser.add_argument('--models', type=str, nargs='+', 
                       choices=['resnet152', 'vit_base', 'vit_base_multicls', 'vit_large', 'densenet161', 
                               'mobilenet_v3_large', 'resnext101_64x4d', 
                               'swin_base_patch4_window7_224', 'convnext_base', 'efficientnet_b7',
                               'efficientnet_v2_s', 'efficientnet_v2_lite0'],
                       default=['vit_base'], help='è¦è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨')
    parser.add_argument('--epochs', type=int, nargs='+', default=[3],
                       help='æ¯ä¸ªæ¨¡å‹çš„epochsæ•°ï¼ˆæ•°é‡è¦ä¸modelsåŒ¹é…ï¼‰')
    
    # æ–­ç‚¹ç»­è®­
    parser.add_argument('--resume', type=str, default=None,
                       help='ä»æŒ‡å®šçš„checkpointæ–‡ä»¶æ¢å¤è®­ç»ƒ (ä¾‹å¦‚: checkpoints/model/best_model.pth)')
    
    # æ•°æ®é…ç½®
    parser.add_argument('--raw', type=str, nargs='+', 
                       help='Rawå›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¯ä»¥å¤šä¸ªï¼‰')
    parser.add_argument('--recap', type=str, nargs='+',
                       help='Recapå›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¯ä»¥å¤šä¸ªï¼‰')
    parser.add_argument('--positive', type=str, nargs='+',
                       help='æ­£æ ·æœ¬æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¯ä»¥å¤šä¸ªï¼‰')
    parser.add_argument('--negative', type=str, nargs='+',
                       help='è´Ÿæ ·æœ¬æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¯ä»¥å¤šä¸ªï¼‰')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--validation-split', type=float, default=0.2,
                       help='éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤: 0.2)')
    parser.add_argument('--save-dir', type=str, default='checkpoints',
                       help='æ¨¡å‹ä¿å­˜ç›®å½• (é»˜è®¤: checkpoints)')
    parser.add_argument('--val-max-samples', type=int, default=0,
                       help='éªŒè¯é›†æœ€å¤§é‡‡æ ·æ•°é‡ï¼Œ0 è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ ·æœ¬')
    parser.add_argument('--pretrained', dest='pretrained', action='store_true',
                       help='ä½¿ç”¨é¢„è®­ç»ƒæƒé‡åˆå§‹åŒ–æ¨¡å‹ (é»˜è®¤å¯ç”¨)')
    parser.add_argument('--no-pretrained', dest='pretrained', action='store_false',
                       help='ç¦ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œå®Œå…¨éšæœºåˆå§‹åŒ–ï¼ˆæ— éœ€å¤–éƒ¨ä¸‹è½½ï¼‰')
    parser.set_defaults(pretrained=True)
    parser.add_argument('--offline', action='store_true',
                       help='å¯ç”¨ç¦»çº¿æ¨¡å¼ï¼Œé˜»æ­¢è®¿é—®Hugging Faceå¹¶è‡ªåŠ¨ç¦ç”¨é¢„è®­ç»ƒæƒé‡')
    
    # Focal Losså‚æ•°
    parser.add_argument('--use-focal-loss', action='store_true', default=True,
                       help='ä½¿ç”¨Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡ (é»˜è®¤: True)')
    parser.add_argument('--focal-alpha', type=float, default=0.65,
                       help='Focal Lossçš„alphaå‚æ•°ï¼Œæ§åˆ¶ç±»åˆ«æƒé‡ (é»˜è®¤: 0.65)')
    parser.add_argument('--focal-gamma', type=float, default=2.0,
                       help='Focal Lossçš„gammaå‚æ•°ï¼Œæ§åˆ¶èšç„¦ç¨‹åº¦ (é»˜è®¤: 2.0)')
    parser.add_argument('--focal-alpha-neg', type=float, default=None,
                       help='Focal Lossè´Ÿç±»(alpha_neg)æƒé‡ (éœ€ä¸ --focal-alpha-pos ä¸€åŒä½¿ç”¨)')
    parser.add_argument('--focal-alpha-pos', type=float, default=None,
                       help='Focal Lossæ­£ç±»(alpha_pos)æƒé‡ (éœ€ä¸ --focal-alpha-neg ä¸€åŒä½¿ç”¨)')
    parser.add_argument('--raw-loss-weight', type=float, default=1.0,
                       help='Rawç±»åˆ«é¢å¤–æŸå¤±æƒé‡ (é»˜è®¤: 1.0)')
    parser.add_argument('--recap-loss-weight', type=float, default=1.0,
                       help='Recapç±»åˆ«é¢å¤–æŸå¤±æƒé‡ (é»˜è®¤: 1.0)')
    
    # Recapä¼˜å…ˆç­–ç•¥
    parser.add_argument('--recap-priority', action='store_true',
                       help='å¯ç”¨Recapä¼˜å…ˆç­–ç•¥ï¼Œå€¾å‘è¯†åˆ«ä¸ºç¿»æ‹')
    parser.add_argument('--recap-oversample', type=float, default=1.0,
                       help='Recapç±»åˆ«è¿‡é‡‡æ ·ç³»æ•° (>1å¯ç”¨æ‰©å¢ï¼Œé»˜è®¤: 1.0)')
    parser.add_argument('--primary-metric', choices=['accuracy', 'recall'], default='accuracy',
                       help='ç”¨äºä¿å­˜æœ€ä½³æ¨¡å‹çš„ä¸»è¦æŒ‡æ ‡ (é»˜è®¤: accuracy)')
    
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()

    if args.offline:
        os.environ.setdefault("HF_HUB_OFFLINE", "1")
        os.environ.setdefault("HF_DATASETS_OFFLINE", "1")
        if args.pretrained:
            logger.info("ğŸ“´ ç¦»çº¿æ¨¡å¼å¯ç”¨: è‡ªåŠ¨ç¦ç”¨é¢„è®­ç»ƒæƒé‡ä»¥é¿å…å¤–éƒ¨ä¸‹è½½")
            args.pretrained = False
    
    # éªŒè¯å‚æ•°
    if len(args.epochs) == 1 and len(args.models) > 1:
        # å¦‚æœåªæŒ‡å®šäº†ä¸€ä¸ªepochsï¼Œåˆ™åº”ç”¨åˆ°æ‰€æœ‰æ¨¡å‹
        args.epochs = args.epochs * len(args.models)
    elif len(args.epochs) != len(args.models):
        logger.error("epochsæ•°é‡å¿…é¡»ä¸modelsæ•°é‡åŒ¹é…ï¼Œæˆ–åªæŒ‡å®šä¸€ä¸ªepochsåº”ç”¨åˆ°æ‰€æœ‰æ¨¡å‹")
        return
    
    # æ„å»ºæ•°æ®é…ç½®
    data_config = {}
    if args.raw and args.recap:
        data_config = {'raw': args.raw, 'recap': args.recap}
    elif args.positive and args.negative:
        data_config = {'positive': args.positive, 'negative': args.negative}
    else:
        # ä½¿ç”¨é»˜è®¤CursorQæ•°æ®è·¯å¾„
        cursorq_base_path = "/Users/karl/Downloads/CursorQ/all_videos_frames_advanced"
        default_raw_paths = [
            f"{cursorq_base_path}/raw_p",
            f"{cursorq_base_path}/raw_v"
        ]
        default_recap_paths = [
            f"{cursorq_base_path}/recap_p", 
            f"{cursorq_base_path}/recap_v"
        ]
        
        # éªŒè¯CursorQæ•°æ®è·¯å¾„æ˜¯å¦å­˜åœ¨
        if all(os.path.exists(path) for path in default_raw_paths + default_recap_paths):
            data_config = {'raw': default_raw_paths, 'recap': default_recap_paths}
            logger.info(f"ğŸ¯ ä½¿ç”¨é»˜è®¤CursorQæ•°æ®é›†: {cursorq_base_path}")
        elif os.path.exists(os.path.join('image', 'raw')) and os.path.exists(os.path.join('image', 'recap')):
            # å¤‡ç”¨ï¼šä½¿ç”¨ image/ ä¸‹çš„ raw å’Œ recap æ–‡ä»¶å¤¹
            data_config = {'raw': [os.path.join('image', 'raw')], 'recap': [os.path.join('image', 'recap')]}
            logger.info("ğŸ“‚ ä½¿ç”¨ image/ ç›®å½•ä¸‹çš„ raw å’Œ recap æ–‡ä»¶å¤¹")
        else:
            logger.error("è¯·æŒ‡å®šæ•°æ®æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæˆ–ç¡®ä¿CursorQæ•°æ®é›†è·¯å¾„æ­£ç¡®ï¼Œæˆ–å½“å‰ç›®å½•ä¸‹æœ‰rawå’Œrecapæ–‡ä»¶å¤¹")
            return
    
    # æ„å»ºè®­ç»ƒè®¡åˆ’
    training_plan = []
    for model, epochs in zip(args.models, args.epochs):
        training_plan.append({'model': model, 'epochs': epochs})
    
    # å¤„ç†Recapä¼˜å…ˆé€»è¾‘
    primary_metric = args.primary_metric
    recap_oversample = args.recap_oversample
    focal_alpha_value = args.focal_alpha
    raw_loss_weight = args.raw_loss_weight
    recap_loss_weight = args.recap_loss_weight
    if args.focal_alpha_neg is not None or args.focal_alpha_pos is not None:
        if args.focal_alpha_neg is None or args.focal_alpha_pos is None:
            logger.error("--focal-alpha-neg ä¸ --focal-alpha-pos éœ€è¦åŒæ—¶æä¾›")
            return
        focal_alpha_value = (args.focal_alpha_neg, args.focal_alpha_pos)
    if args.recap_priority:
        if recap_oversample <= 1.0:
            recap_oversample = 1.8
            logger.info(f"ğŸ¯ Recapä¼˜å…ˆç­–ç•¥å¯ç”¨: è¿‡é‡‡æ ·ç³»æ•°è‡ªåŠ¨è®¾ç½®ä¸º {recap_oversample}")
        if args.focal_alpha_neg is None and args.focal_alpha_pos is None and not isinstance(focal_alpha_value, (list, tuple)) and focal_alpha_value < 0.7:
            focal_alpha_value = 0.75
            logger.info("ğŸ¯ Recapä¼˜å…ˆç­–ç•¥å¯ç”¨: Focal Loss alpha æå‡è‡³ 0.75")
        if not args.use_focal_loss:
            logger.info("ğŸ¯ Recapä¼˜å…ˆç­–ç•¥å¯ç”¨: è‡ªåŠ¨å¯ç”¨Focal Loss")
            args.use_focal_loss = True
        if args.raw_loss_weight == 1.0 and args.recap_loss_weight == 1.0:
            raw_loss_weight = 0.85
            recap_loss_weight = 1.15
            logger.info("ğŸ¯ Recapä¼˜å…ˆç­–ç•¥å¯ç”¨: è°ƒæ•´æŸå¤±æƒé‡ raw=0.85, recap=1.15")
        primary_metric = 'recall'
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = UnifiedTrainer(logger, device=args.device)
    trainer.train_multiple_models(
        training_plan=training_plan,
        data_config=data_config,
        validation_split=args.validation_split,
        save_dir=args.save_dir,
        resume_from=args.resume,
        use_focal_loss=args.use_focal_loss,
        focal_alpha=focal_alpha_value,
        focal_gamma=args.focal_gamma,
        primary_metric=primary_metric,
        recap_priority=args.recap_priority,
        recap_oversample=recap_oversample,
        use_pretrained=args.pretrained,
        val_max_samples=args.val_max_samples,
        raw_loss_weight=raw_loss_weight,
        recap_loss_weight=recap_loss_weight,
        focal_alpha_neg=args.focal_alpha_neg,
        focal_alpha_pos=args.focal_alpha_pos
    )

if __name__ == "__main__":
    main() 
