#!/usr/bin/env python3
"""
ç»Ÿä¸€æ¨ç†è„šæœ¬ - æ•´åˆæ‰€æœ‰æ¨ç†å’Œåˆ†ç±»åŠŸèƒ½
æ”¯æŒåŠŸèƒ½ï¼š
1. å•å›¾åˆ†ç±»
2. å•ä¸ªæ–‡ä»¶å¤¹åˆ†ç±»
3. åŒæ–‡ä»¶å¤¹æ··æ·†çŸ©é˜µï¼ˆæ”¯æŒä¿å­˜é”™è¯¯å›¾ç‰‡ï¼‰
4. æ¨¡å‹å¯¹æ¯”
"""

import os
import torch
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import json
import shutil
from datetime import datetime
import argparse
from tqdm import tqdm
from pathlib import Path
import glob
import logging

# æ ¹æ®ç¯å¢ƒé€‰æ‹©æ€§ç¦ç”¨é‡å‹ä¾èµ–ï¼ˆç”¨äºå—é™ç¯å¢ƒï¼‰
LIGHT_INFERENCE = os.environ.get("PHONERECAP_LIGHT_INFERENCE", "").lower() in {"1", "true", "yes"}
if not LIGHT_INFERENCE:
    import numpy as np  # type: ignore
    import matplotlib.pyplot as plt  # type: ignore
    import seaborn as sns  # type: ignore
else:
    np = None
    plt = None
    sns = None

# å¯¼å…¥æ¨¡å‹
from model import get_model
import torch.nn as nn
import timm

# å¯¼å…¥ViT-Large Siameseæ¨ç†ç½‘ç»œ
from vit_large_siamese_inference import ViTLargeSiameseInference

# MobileNet-Siameseæ¨ç†ç½‘ç»œ
class MobileNetV3SiameseInference(nn.Module):
    """MobileNet-V3-Siameseæ¨ç†ç½‘ç»œ"""
    
    def __init__(self, num_classes=2):
        super(MobileNetV3SiameseInference, self).__init__()
        self.feat_dim = self._get_mobilenet_backbone()
        
        # ä¸è®­ç»ƒä»£ç ä¸€è‡´çš„ç‰¹å¾é€‚é…å±‚
        self.feat_adapter = nn.Sequential(
            nn.Linear(self.feat_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.BatchNorm1d(128)
        )
        
        # åˆ†ç±»å¤´
        self.classifier = nn.Linear(128, num_classes)
        
        # æ¸©åº¦å‚æ•°ï¼ˆä¸è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
        self.temperature = nn.Parameter(torch.tensor(0.1))

    def _get_mobilenet_backbone(self):
        """åˆå§‹åŒ–MobileNet-V3-Largeéª¨å¹²ç½‘ç»œ"""
        # åˆ›å»ºMobileNet-V3-Largeæ¨¡å‹
        model = timm.create_model('mobilenetv3_large_100', pretrained=False, features_only=True)
        feat_dim = 960  # MobileNet-V3-Largeå®é™…è¾“å‡ºç‰¹å¾ç»´åº¦
        
        # æ„å»ºç‰¹å¾æå–å™¨ - æå–æœ€åçš„ç‰¹å¾å›¾
        self.feature_extractor = model
        
        return feat_dim

    def forward_once(self, x):
        # MobileNet features_only è¿”å›å¤šå°ºåº¦ç‰¹å¾ï¼Œå–æœ€åä¸€ä¸ª
        features = self.feature_extractor(x)
        x = features[-1]  # å–æœ€é«˜å±‚ç‰¹å¾ [B, C, H, W]
        x = F.adaptive_avg_pool2d(x, (1, 1))  # [B, C, 1, 1]
        x = x.view(x.size(0), -1)  # [B, C]
        feat = self.feat_adapter(x)
        # L2å½’ä¸€åŒ–ï¼ˆä¸è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
        feat_norm = F.normalize(feat, p=2, dim=1)
        # æ¸©åº¦ç¼©æ”¾ï¼ˆä¸è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
        logits = self.classifier(feat_norm) / self.temperature
        return feat_norm, logits

    def forward(self, x):
        feat_norm, logits = self.forward_once(x)
        return logits

# é…ç½®æ—¥å¿—
def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

class UnifiedInference:
    """ç»Ÿä¸€æ¨ç†å™¨"""
    
    def __init__(self, model_name, model_path, device='auto'):
        """
        åˆå§‹åŒ–æ¨ç†å™¨
        
        Args:
            model_name: æ¨¡å‹åç§° ('resnet152', 'vit_base', 'vit_large', 'mobilenet_v3_large', 'mobilenet_v3_large_siamese')
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            device: è®¾å¤‡é€‰æ‹© ('auto', 'cpu', 'cuda')
        """
        self.model_name = model_name
        self.model_path = model_path
        self.logger = logging.getLogger(__name__)
        
        # è®¾ç½®è®¾å¤‡
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        self.logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # å®šä¹‰æ•°æ®å˜æ¢
        input_sizes = {
            'efficientnet_v2_s': 256,
            'efficientnet_v2_lite0': 224,
            'mobilenet_v3_large': 224,
            'mobilenet_v3_large_siamese': 224,
            'vit_large': 224,
            'vit_large_siamese': 224,
            'vit_base': 224,
            'resnet152': 224,
            'densenet161': 224,
            'resnext101_64x4d': 224,
            'swin_base_patch4_window7_224': 224,
            'convnext_base': 224,
            'efficientnet_b7': 600
        }
        input_size = input_sizes.get(self.model_name, 224)
        self.transform = transforms.Compose([
            transforms.Resize((input_size, input_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # ç±»åˆ«æ˜ å°„
        self.class_names = ['raw', 'recap']
        self.class_to_idx = {'raw': 0, 'recap': 1}
        self.idx_to_class = {0: 'raw', 1: 'recap'}
        
        # åŠ è½½æ¨¡å‹
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹"""
        try:
            self.logger.info(f"æ­£åœ¨åŠ è½½ {self.model_name} æ¨¡å‹...")
            self.logger.info(f"æ¨¡å‹è·¯å¾„: {self.model_path}")
            
            # ç‰¹æ®Šå¤„ç†Siameseæ¨¡å‹
            if self.model_name == 'mobilenet_v3_large_siamese':
                self.model = MobileNetV3SiameseInference(num_classes=2)
            elif self.model_name == 'vit_large_siamese':
                self.model = ViTLargeSiameseInference(num_classes=2)
            else:
                # åˆ›å»ºæ ‡å‡†æ¨¡å‹
                self.model = get_model(self.model_name, num_classes=2, pretrained=False)
            
            # åŠ è½½æƒé‡
            if os.path.exists(self.model_path):
                checkpoint = torch.load(self.model_path, map_location=self.device)
                
                # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
                if 'model_state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                    val_acc = checkpoint.get('best_val_acc', 'N/A')
                    if isinstance(val_acc, (int, float)):
                        self.logger.info(f"æ¨¡å‹éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")
                    else:
                        self.logger.info(f"æ¨¡å‹éªŒè¯å‡†ç¡®ç‡: {val_acc}")
                elif 'val_score' in checkpoint:  # Siameseæ¨¡å‹ä½¿ç”¨val_score
                    val_score = checkpoint.get('val_score', 'N/A')
                    if isinstance(val_score, (int, float)):
                        self.logger.info(f"æ¨¡å‹éªŒè¯è¯„åˆ†: {val_score:.4f}")
                    else:
                        self.logger.info(f"æ¨¡å‹éªŒè¯è¯„åˆ†: {val_score}")
                else:
                    self.model.load_state_dict(checkpoint)
                
                self.model.to(self.device)
                self.model.eval()
                self.logger.info(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {self.model_name}")
            else:
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            raise
    
    def predict_single(self, image_path, return_probabilities=True):
        """
        å•å›¾é¢„æµ‹
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            return_probabilities: æ˜¯å¦è¿”å›æ¦‚ç‡
            
        Returns:
            dict: é¢„æµ‹ç»“æœ
        """
        try:
            # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = F.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                predicted_class = self.idx_to_class[predicted.item()]
                confidence_score = confidence.item()
                
                result = {
                    'image': image_path,
                    'class': predicted_class,
                    'confidence': confidence_score,
                    'prediction_index': predicted.item()
                }
                
                if return_probabilities:
                    result['probabilities'] = {
                        'raw': probabilities[0][0].item(),
                        'recap': probabilities[0][1].item()
                    }
                
                return result
                
        except Exception as e:
            self.logger.error(f"é¢„æµ‹å¤±è´¥ {image_path}: {str(e)}")
            return None
    
    def predict_folder(self, folder_path, output_file=None, save_details=True):
        """
        æ–‡ä»¶å¤¹æ‰¹é‡é¢„æµ‹
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            save_details: æ˜¯å¦ä¿å­˜è¯¦ç»†ç»“æœ
            
        Returns:
            list: é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        self.logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†æ–‡ä»¶å¤¹: {folder_path}")
        
        # è·å–å›¾ç‰‡æ–‡ä»¶
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        image_files = []
        for ext in image_extensions:
            image_files.extend(glob.glob(os.path.join(folder_path, ext), recursive=False))
            image_files.extend(glob.glob(os.path.join(folder_path, ext.upper()), recursive=False))
        
        if not image_files:
            self.logger.warning(f"åœ¨ {folder_path} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return []
        
        self.logger.info(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
        
        # æ‰¹é‡é¢„æµ‹
        results = []
        raw_count = 0
        recap_count = 0
        
        for image_path in tqdm(image_files, desc="å¤„ç†å›¾ç‰‡"):
            result = self.predict_single(image_path, return_probabilities=save_details)
            if result:
                results.append(result)
                if result['class'] == 'raw':
                    raw_count += 1
                else:
                    recap_count += 1
        
        # ç»Ÿè®¡ç»“æœ
        self.logger.info(f"ğŸ“Š åˆ†ç±»ç»“æœç»Ÿè®¡:")
        self.logger.info(f"  Raw: {raw_count} å¼  ({raw_count/len(results)*100:.1f}%)")
        self.logger.info(f"  Recap: {recap_count} å¼  ({recap_count/len(results)*100:.1f}%)")
        self.logger.info(f"  æ€»è®¡: {len(results)} å¼ ")
        
        # ä¿å­˜ç»“æœ
        if output_file and save_details:
            summary_data = {
                'model_name': self.model_name,
                'model_path': self.model_path,
                'folder_path': folder_path,
                'timestamp': datetime.now().isoformat(),
                'statistics': {
                    'total_images': len(results),
                    'raw_count': raw_count,
                    'recap_count': recap_count,
                    'raw_percentage': raw_count/len(results)*100,
                    'recap_percentage': recap_count/len(results)*100
                },
                'detailed_results': results
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜: {output_file}")
        
        return results
    
    def compute_confusion_matrix(self, raw_folder, recap_folder, output_dir=None, save_errors=False):
        """
        è®¡ç®—æ··æ·†çŸ©é˜µ
        
        Args:
            raw_folder: rawå›¾ç‰‡æ–‡ä»¶å¤¹
            recap_folder: recapå›¾ç‰‡æ–‡ä»¶å¤¹  
            output_dir: è¾“å‡ºç›®å½•
            save_errors: æ˜¯å¦ä¿å­˜é”™è¯¯åˆ†ç±»çš„å›¾ç‰‡
            
        Returns:
            dict: æ··æ·†çŸ©é˜µç»“æœ
        """
        self.logger.info(f"ğŸ“Š å¼€å§‹è®¡ç®—æ··æ·†çŸ©é˜µ")
        self.logger.info(f"Rawæ–‡ä»¶å¤¹: {raw_folder}")
        self.logger.info(f"Recapæ–‡ä»¶å¤¹: {recap_folder}")
        
        # è·å–æ‰€æœ‰å›¾ç‰‡
        raw_images = self._get_images_from_folder(raw_folder)
        recap_images = self._get_images_from_folder(recap_folder)
        
        self.logger.info(f"Rawå›¾ç‰‡æ•°é‡: {len(raw_images)}")
        self.logger.info(f"Recapå›¾ç‰‡æ•°é‡: {len(recap_images)}")
        
        # é¢„æµ‹æ‰€æœ‰å›¾ç‰‡
        all_images = []
        true_labels = []
        predicted_labels = []
        error_images = {'raw_as_recap': [], 'recap_as_raw': []}
        
        # å¤„ç†rawå›¾ç‰‡
        self.logger.info("ğŸ”„ å¤„ç†Rawå›¾ç‰‡...")
        for img_path in tqdm(raw_images, desc="Rawå›¾ç‰‡"):
            result = self.predict_single(img_path, return_probabilities=True)
            if result:
                all_images.append(result)
                true_labels.append(0)  # raw = 0
                predicted_labels.append(result['prediction_index'])
                
                # æ£€æŸ¥åˆ†ç±»é”™è¯¯
                if result['class'] == 'recap':  # rawè¢«è¯¯åˆ†ç±»ä¸ºrecap
                    error_images['raw_as_recap'].append(result)
        
        # å¤„ç†recapå›¾ç‰‡
        self.logger.info("ğŸ”„ å¤„ç†Recapå›¾ç‰‡...")
        for img_path in tqdm(recap_images, desc="Recapå›¾ç‰‡"):
            result = self.predict_single(img_path, return_probabilities=True)
            if result:
                all_images.append(result)
                true_labels.append(1)  # recap = 1
                predicted_labels.append(result['prediction_index'])
                
                # æ£€æŸ¥åˆ†ç±»é”™è¯¯
                if result['class'] == 'raw':  # recapè¢«è¯¯åˆ†ç±»ä¸ºraw
                    error_images['recap_as_raw'].append(result)
        
        # è®¡ç®—æ··æ·†çŸ©é˜µ
        cm = [[0, 0], [0, 0]]
        for t, p in zip(true_labels, predicted_labels):
            if 0 <= t < 2 and 0 <= p < 2:
                cm[t][p] += 1
        total_predictions = sum(sum(row) for row in cm)
        accuracy = (cm[0][0] + cm[1][1]) / total_predictions if total_predictions else 0.0
        
        # è®¡ç®—å„ç±»æŒ‡æ ‡
        tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]
        
        # Rawç±»åˆ«æŒ‡æ ‡ (ç±»åˆ«0)
        raw_precision = tn / (tn + fn) if (tn + fn) > 0 else 0
        raw_recall = tn / (tn + fp) if (tn + fp) > 0 else 0
        raw_f1 = 2 * (raw_precision * raw_recall) / (raw_precision + raw_recall) if (raw_precision + raw_recall) > 0 else 0
        
        # Recapç±»åˆ«æŒ‡æ ‡ (ç±»åˆ«1) 
        recap_precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recap_recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        recap_f1 = 2 * (recap_precision * recap_recall) / (recap_precision + recap_recall) if (recap_precision + recap_recall) > 0 else 0
        
        # ç»“æœç»Ÿè®¡
        results = {
            'model_name': self.model_name,
            'model_path': self.model_path,
            'timestamp': datetime.now().isoformat(),
            'dataset_info': {
                'raw_folder': raw_folder,
                'recap_folder': recap_folder,
                'raw_count': len(raw_images),
                'recap_count': len(recap_images),
                'total_count': len(all_images)
            },
            'confusion_matrix': cm,
            'accuracy': accuracy,
            'detailed_metrics': {
                'raw': {
                    'precision': raw_precision,
                    'recall': raw_recall,
                    'f1_score': raw_f1,
                    'support': len(raw_images)
                },
                'recap': {
                    'precision': recap_precision,
                    'recall': recap_recall,
                    'f1_score': recap_f1,
                    'support': len(recap_images)
                }
            },
            'error_analysis': {
                'raw_misclassified_as_recap': len(error_images['raw_as_recap']),
                'recap_misclassified_as_raw': len(error_images['recap_as_raw']),
                'total_errors': len(error_images['raw_as_recap']) + len(error_images['recap_as_raw'])
            },
            'all_predictions': all_images
        }
        
        # è¾“å‡ºç»“æœ
        self.logger.info(f"\nğŸ“Š æ··æ·†çŸ©é˜µç»“æœ:")
        self.logger.info(f"æ€»ä½“å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        self.logger.info(f"Rawå‡†ç¡®ç‡: {raw_recall:.4f} ({raw_recall*100:.2f}%)")
        self.logger.info(f"Recapå‡†ç¡®ç‡: {recap_recall:.4f} ({recap_recall*100:.2f}%)")
        self.logger.info(f"é”™è¯¯åˆ†ç±»: {results['error_analysis']['total_errors']} å¼ ")
        self.logger.info(f"  Rawè¯¯åˆ†ä¸ºRecap: {len(error_images['raw_as_recap'])} å¼ ")
        self.logger.info(f"  Recapè¯¯åˆ†ä¸ºRaw: {len(error_images['recap_as_raw'])} å¼ ")
        
        # ä¿å­˜ç»“æœå’Œå›¾è¡¨
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ä¿å­˜JSONç»“æœ
            json_file = os.path.join(output_dir, f'confusion_matrix_{self.model_name}_{timestamp}.json')
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            self.logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {json_file}")

            if plt and sns and np is not None:
                cm_array = np.array(cm)
                plt.figure(figsize=(8, 6))
                sns.heatmap(cm_array, annot=True, fmt='d', cmap='Blues',
                           xticklabels=self.class_names, yticklabels=self.class_names)
                plt.title(f'Confusion Matrix - {self.model_name}\nAccuracy: {accuracy:.4f}')
                plt.ylabel('True Label')
                plt.xlabel('Predicted Label')

                plot_file = os.path.join(output_dir, f'confusion_matrix_{self.model_name}_{timestamp}.png')
                plt.savefig(plot_file, dpi=300, bbox_inches='tight')
                plt.close()
                self.logger.info(f"  å›¾è¡¨: {plot_file}")
            elif output_dir and not LIGHT_INFERENCE:
                self.logger.warning("âš ï¸ æ— æ³•ç»˜åˆ¶æ··æ·†çŸ©é˜µå›¾ï¼Œå¯èƒ½ç¼ºå°‘matplotlib/seabornä¾èµ–")
        
        # ä¿å­˜é”™è¯¯å›¾ç‰‡
        if save_errors and error_images['raw_as_recap'] or error_images['recap_as_raw']:
            self._save_error_images(error_images, output_dir or '.')
        
        return results
    
    def _get_images_from_folder(self, folder_path):
        """ä»æ–‡ä»¶å¤¹è·å–å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨"""
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        image_files = []
        for ext in image_extensions:
            image_files.extend(glob.glob(os.path.join(folder_path, ext), recursive=False))
            image_files.extend(glob.glob(os.path.join(folder_path, ext.upper()), recursive=False))
        return sorted(image_files)
    
    def _save_error_images(self, error_images, output_dir):
        """ä¿å­˜åˆ†ç±»é”™è¯¯çš„å›¾ç‰‡"""
        self.logger.info("ğŸ’¾ ä¿å­˜åˆ†ç±»é”™è¯¯çš„å›¾ç‰‡...")
        
        # åˆ›å»ºé”™è¯¯å›¾ç‰‡æ–‡ä»¶å¤¹
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        error_dir = os.path.join(output_dir, f'{self.model_name}_errors_{timestamp}')
        
        raw_error_dir = os.path.join(error_dir, 'raw_misclassified_as_recap')
        recap_error_dir = os.path.join(error_dir, 'recap_misclassified_as_raw')
        
        os.makedirs(raw_error_dir, exist_ok=True)
        os.makedirs(recap_error_dir, exist_ok=True)
        
        # å¤åˆ¶é”™è¯¯åˆ†ç±»çš„å›¾ç‰‡
        for result in error_images['raw_as_recap']:
            src_path = result['image']
            filename = os.path.basename(src_path)
            dst_path = os.path.join(raw_error_dir, filename)
            shutil.copy2(src_path, dst_path)
        
        for result in error_images['recap_as_raw']:
            src_path = result['image']
            filename = os.path.basename(src_path)
            dst_path = os.path.join(recap_error_dir, filename)
            shutil.copy2(src_path, dst_path)
        
        # ä¿å­˜é”™è¯¯è¯¦æƒ…
        error_details = {
            'model_name': self.model_name,
            'timestamp': datetime.now().isoformat(),
            'raw_misclassified_as_recap': error_images['raw_as_recap'],
            'recap_misclassified_as_raw': error_images['recap_as_raw']
        }
        
        details_file = os.path.join(error_dir, 'error_details.json')
        with open(details_file, 'w', encoding='utf-8') as f:
            json.dump(error_details, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ğŸ’¾ é”™è¯¯å›¾ç‰‡å·²ä¿å­˜åˆ°: {error_dir}")
        self.logger.info(f"  Rawè¯¯åˆ†ç±»: {len(error_images['raw_as_recap'])} å¼ ")
        self.logger.info(f"  Recapè¯¯åˆ†ç±»: {len(error_images['recap_as_raw'])} å¼ ")

def get_available_models():
    """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    models = {}
    
    # æ£€æŸ¥checkpointsç›®å½•
    checkpoint_dir = 'checkpoints'
    if os.path.exists(checkpoint_dir):
        for folder in os.listdir(checkpoint_dir):
            folder_path = os.path.join(checkpoint_dir, folder)
            if os.path.isdir(folder_path):
                # æ£€æŸ¥Siameseæ¨¡å‹
                siamese_model_path = os.path.join(folder_path, 'best_mobilenet_v3_large_siamese.pth')
                if os.path.exists(siamese_model_path):
                    models['mobilenet_v3_large_siamese'] = siamese_model_path
                
                # æ£€æŸ¥ViT-Large Siameseæ¨¡å‹
                vit_siamese_model_path = os.path.join(folder_path, 'best_vit_large_siamese.pth')
                if os.path.exists(vit_siamese_model_path):
                    models['vit_large_siamese'] = vit_siamese_model_path
                
                # æ£€æŸ¥æ ‡å‡†æ¨¡å‹
                best_model_path = os.path.join(folder_path, 'best_model.pth')
                if os.path.exists(best_model_path):
                    # ä»æ–‡ä»¶å¤¹åç§°æ¨æ–­æ¨¡å‹ç±»å‹
                    if 'resnet152' in folder:
                        models['resnet152'] = best_model_path
                    elif 'vit_base' in folder:
                        models['vit_base'] = best_model_path
                    elif 'vit_large' in folder:
                        models['vit_large'] = best_model_path
                    elif 'mobilenet_v3_large' in folder and 'siamese' not in folder:
                        models['mobilenet_v3_large'] = best_model_path
                    elif 'resnext101_64x4d' in folder:
                        models['resnext101_64x4d'] = best_model_path
                    elif 'swin_base_patch4_window7_224' in folder:
                        models['swin_base_patch4_window7_224'] = best_model_path
                    elif 'convnext_base' in folder:
                        models['convnext_base'] = best_model_path
                    elif 'efficientnet_b7' in folder:
                        models['efficientnet_b7'] = best_model_path
                    elif 'densenet161' in folder:
                        models['densenet161'] = best_model_path
                    elif 'efficientnet_v2_s' in folder:
                        models['efficientnet_v2_s'] = best_model_path
                    elif 'efficientnet_v2_lite0' in folder:
                        models['efficientnet_v2_lite0'] = best_model_path
    
    return models

def compare_models(raw_folder, recap_folder, output_dir=None):
    """æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„æ€§èƒ½"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ”„ å¼€å§‹æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ")
    
    available_models = get_available_models()
    if not available_models:
        logger.error("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹")
        return
    
    logger.info(f"æ‰¾åˆ° {len(available_models)} ä¸ªæ¨¡å‹: {list(available_models.keys())}")
    
    comparison_results = []
    
    for model_name, model_path in available_models.items():
        logger.info(f"ğŸ”„ æµ‹è¯•æ¨¡å‹: {model_name}")
        
        try:
            inference = UnifiedInference(model_name, model_path)
            result = inference.compute_confusion_matrix(raw_folder, recap_folder, output_dir)
            comparison_results.append(result)
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ {model_name} æµ‹è¯•å¤±è´¥: {str(e)}")
    
    # ä¿å­˜æ¯”è¾ƒç»“æœ
    if output_dir and comparison_results:
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        comparison_file = os.path.join(output_dir, f'model_comparison_{timestamp}.json')
        with open(comparison_file, 'w', encoding='utf-8') as f:
            json.dump(comparison_results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ æ¨¡å‹æ¯”è¾ƒç»“æœå·²ä¿å­˜: {comparison_file}")
        
        # è¾“å‡ºæ¯”è¾ƒæ‘˜è¦
        logger.info(f"\nğŸ“Š æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ:")
        for result in comparison_results:
            logger.info(f"  {result['model_name']}: {result['accuracy']:.4f} ({result['accuracy']*100:.2f}%)")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€æ¨ç†å·¥å…·')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--mode', choices=['single', 'folder', 'confusion', 'compare'], 
                       required=True, help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--model', choices=['resnet152', 'vit_base', 'vit_base_multicls', 'vit_large', 'vit_large_siamese', 'densenet161', 'mobilenet_v3_large', 'mobilenet_v3_large_siamese', 'resnext101_64x4d', 'swin_base_patch4_window7_224', 'convnext_base', 'efficientnet_b7', 'efficientnet_v2_s', 'efficientnet_v2_lite0'], 
                       help='æ¨¡å‹åç§°ï¼ˆsingle/folder/confusionæ¨¡å¼éœ€è¦ï¼‰')
    parser.add_argument('--model_path', help='è‡ªå®šä¹‰æ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--device', choices=['auto', 'cpu', 'cuda'], default='auto',
                       help='è®¾å¤‡é€‰æ‹©')
    parser.add_argument('--output', help='è¾“å‡ºç›®å½•')
    
    # è¾“å…¥å‚æ•°
    parser.add_argument('--image', help='å•å¼ å›¾ç‰‡è·¯å¾„ï¼ˆsingleæ¨¡å¼ï¼‰')
    parser.add_argument('--folder', help='å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆfolderæ¨¡å¼ï¼‰')
    parser.add_argument('--raw_folder', help='Rawå›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆconfusion/compareæ¨¡å¼ï¼‰')
    parser.add_argument('--recap_folder', help='Recapå›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆconfusion/compareæ¨¡å¼ï¼‰')
    
    # é¢å¤–é€‰é¡¹
    parser.add_argument('--save_errors', action='store_true', 
                       help='ä¿å­˜åˆ†ç±»é”™è¯¯çš„å›¾ç‰‡ï¼ˆä»…confusionæ¨¡å¼ï¼‰')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    
    # è·å–å¯ç”¨æ¨¡å‹
    available_models = get_available_models()
    logger.info(f"å¯ç”¨æ¨¡å‹: {list(available_models.keys())}")
    
    if args.mode == 'compare':
        # æ¨¡å‹æ¯”è¾ƒæ¨¡å¼
        if not args.raw_folder or not args.recap_folder:
            logger.error("compareæ¨¡å¼éœ€è¦æŒ‡å®š --raw_folder å’Œ --recap_folder")
            return
        
        compare_models(args.raw_folder, args.recap_folder, args.output)
    
    else:
        # å•æ¨¡å‹æ¨¡å¼
        if not args.model:
            logger.error("single/folder/confusionæ¨¡å¼éœ€è¦æŒ‡å®š --model")
            return
        
        # è·å–æ¨¡å‹è·¯å¾„
        if args.model_path:
            model_path = args.model_path
        else:
            if args.model not in available_models:
                logger.error(f"æœªæ‰¾åˆ°æ¨¡å‹ {args.model}ï¼Œå¯ç”¨æ¨¡å‹: {list(available_models.keys())}")
                return
            model_path = available_models[args.model]
        
        # åˆ›å»ºæ¨ç†å™¨
        inference = UnifiedInference(args.model, model_path, args.device)
        
        if args.mode == 'single':
            # å•å›¾åˆ†ç±»
            if not args.image:
                logger.error("singleæ¨¡å¼éœ€è¦æŒ‡å®š --image")
                return
            
            result = inference.predict_single(args.image)
            if result:
                logger.info(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
                logger.info(f"å›¾ç‰‡: {args.image}")
                logger.info(f"ç±»åˆ«: {result['class']}")
                logger.info(f"ç½®ä¿¡åº¦: {result['confidence']:.4f}")
                if 'probabilities' in result:
                    logger.info(f"æ¦‚ç‡åˆ†å¸ƒ: Raw={result['probabilities']['raw']:.4f}, Recap={result['probabilities']['recap']:.4f}")
        
        elif args.mode == 'folder':
            # æ–‡ä»¶å¤¹åˆ†ç±»
            if not args.folder:
                logger.error("folderæ¨¡å¼éœ€è¦æŒ‡å®š --folder")
                return
            
            output_file = None
            if args.output:
                os.makedirs(args.output, exist_ok=True)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_file = os.path.join(args.output, f'folder_results_{args.model}_{timestamp}.json')
            
            inference.predict_folder(args.folder, output_file)
        
        elif args.mode == 'confusion':
            # æ··æ·†çŸ©é˜µ
            if not args.raw_folder or not args.recap_folder:
                logger.error("confusionæ¨¡å¼éœ€è¦æŒ‡å®š --raw_folder å’Œ --recap_folder")
                return
            
            inference.compute_confusion_matrix(
                args.raw_folder, 
                args.recap_folder, 
                args.output,
                save_errors=args.save_errors
            )

if __name__ == '__main__':
    main() 
