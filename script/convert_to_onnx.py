#!/usr/bin/env python3
"""
PyTorchæ¨¡å‹è½¬ONNXæ ¼å¼è„šæœ¬
å°†è®­ç»ƒå¥½çš„PyTorchæ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼ï¼Œç”¨äºæ›´å¿«çš„æ¨ç†
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import argparse
import json
from model import get_model
from vit_large_siamese_inference import ViTLargeSiameseInference
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def convert_to_onnx(model_name, model_path, output_path, input_shape=(1, 3, 224, 224)):
    """
    å°†PyTorchæ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼

    Args:
        model_name: æ¨¡å‹åç§° ('resnet152', 'vit_base', 'vit_large', 'vit_large_siamese')
        model_path: PyTorchæ¨¡å‹æƒé‡è·¯å¾„
        output_path: ONNXæ¨¡å‹è¾“å‡ºè·¯å¾„
        input_shape: è¾“å…¥å¼ é‡å½¢çŠ¶ (batch_size, channels, height, width)
    """
    try:
        logger.info(f"ğŸ”„ å¼€å§‹è½¬æ¢æ¨¡å‹: {model_name}")
        logger.info(f"è¾“å…¥æ¨¡å‹: {model_path}")
        logger.info(f"è¾“å‡ºæ¨¡å‹: {output_path}")
        logger.info(f"è¾“å…¥å½¢çŠ¶: {input_shape}")

        # è®¾ç½®è®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")

        # åˆ›å»ºæ¨¡å‹
        logger.info("åˆ›å»ºæ¨¡å‹...")
        if model_name == 'vit_large_siamese':
            model = ViTLargeSiameseInference(num_classes=2)
        else:
            model = get_model(model_name, num_classes=2, pretrained=False)

        # åŠ è½½æƒé‡
        logger.info("åŠ è½½æ¨¡å‹æƒé‡...")
        if os.path.exists(model_path):
            checkpoint = torch.load(model_path, map_location=device)

            # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
                best_val_acc = checkpoint.get('best_val_acc', 'N/A')
                if best_val_acc != 'N/A':
                    logger.info(f"æ¨¡å‹éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
                else:
                    logger.info("æ¨¡å‹éªŒè¯å‡†ç¡®ç‡: N/A")
            else:
                model.load_state_dict(checkpoint)

            model.to(device)
            model.eval()
            logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        else:
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        # åˆ›å»ºç¤ºä¾‹è¾“å…¥
        logger.info("åˆ›å»ºç¤ºä¾‹è¾“å…¥...")
        dummy_input = torch.randn(input_shape, device=device)

        # å¯¼å‡ºä¸ºONNX
        logger.info("å¯¼å‡ºONNXæ¨¡å‹...")
        torch.onnx.export(
            model,                     # è¦è½¬æ¢çš„æ¨¡å‹
            dummy_input,              # ç¤ºä¾‹è¾“å…¥
            output_path,              # è¾“å‡ºæ–‡ä»¶è·¯å¾„
            export_params=True,       # å¯¼å‡ºæ¨¡å‹å‚æ•°
            opset_version=16,         # ONNXæ“ä½œé›†ç‰ˆæœ¬ï¼ˆæ”¯æŒscaled_dot_product_attentionï¼‰
            do_constant_folding=True, # ä¼˜åŒ–å¸¸é‡æŠ˜å 
            input_names=['input'],    # è¾“å…¥åç§°
            output_names=['output'],  # è¾“å‡ºåç§°
            dynamic_axes={            # åŠ¨æ€è½´ï¼ˆæ”¯æŒæ‰¹å¤„ç†ï¼‰
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        
        logger.info("âœ… ONNXæ¨¡å‹å¯¼å‡ºæˆåŠŸ")
        
        # éªŒè¯ONNXæ¨¡å‹
        logger.info("éªŒè¯ONNXæ¨¡å‹...")
        import onnx
        onnx_model = onnx.load(output_path)
        onnx.checker.check_model(onnx_model)
        logger.info("âœ… ONNXæ¨¡å‹éªŒè¯é€šè¿‡")
        
        # ä¿å­˜æ¨¡å‹ä¿¡æ¯
        model_info = {
            'model_name': model_name,
            'original_path': model_path,
            'onnx_path': output_path,
            'input_shape': input_shape,
            'device': str(device),
            'opset_version': 16,
            'num_classes': 2,
            'class_names': ['raw', 'recap']
        }
        
        info_path = output_path.replace('.onnx', '_info.json')
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜: {info_path}")
        
        # è¾“å‡ºæ¨¡å‹å¤§å°ä¿¡æ¯
        original_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
        onnx_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
        
        logger.info(f"ğŸ“Š æ¨¡å‹å¤§å°å¯¹æ¯”:")
        logger.info(f"  PyTorchæ¨¡å‹: {original_size:.2f} MB")
        logger.info(f"  ONNXæ¨¡å‹: {onnx_size:.2f} MB")
        logger.info(f"  å‹ç¼©æ¯”: {original_size/onnx_size:.2f}x")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ è½¬æ¢å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='PyTorchæ¨¡å‹è½¬ONNXæ ¼å¼')
    
    parser.add_argument('--model_name', choices=['resnet152', 'vit_base', 'vit_base_multicls', 'vit_large', 'densenet161', 'mobilenet_v3_large', 'resnext101_64x4d', 'swin_base_patch4_window7_224', 'convnext_base', 'efficientnet_b7', 'vit_large_siamese'],
                       required=True, help='æ¨¡å‹åç§°')
    parser.add_argument('--model_path', required=True, help='PyTorchæ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--output_path', help='ONNXæ¨¡å‹è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰')
    parser.add_argument('--batch_size', type=int, default=1, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--height', type=int, default=224, help='è¾“å…¥å›¾åƒé«˜åº¦')
    parser.add_argument('--width', type=int, default=224, help='è¾“å…¥å›¾åƒå®½åº¦')
    
    args = parser.parse_args()
    
    # æ ¹æ®æ¨¡å‹åç§°è‡ªåŠ¨è®¾ç½®è¾“å…¥å°ºå¯¸
    if args.model_name == 'efficientnet_b7':
        args.height = args.width = 600
    
    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if not args.output_path:
        base_name = os.path.splitext(os.path.basename(args.model_path))[0]
        output_path = f"{base_name}.onnx"
    else:
        output_path = args.output_path
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)
    
    # è®¾ç½®è¾“å…¥å½¢çŠ¶
    input_shape = (args.batch_size, 3, args.height, args.width)
    
    # æ‰§è¡Œè½¬æ¢
    success = convert_to_onnx(
        model_name=args.model_name,
        model_path=args.model_path,
        output_path=output_path,
        input_shape=input_shape
    )
    
    if success:
        logger.info(f"ğŸ‰ è½¬æ¢å®Œæˆï¼ONNXæ¨¡å‹å·²ä¿å­˜åˆ°: {output_path}")
    else:
        logger.error("âŒ è½¬æ¢å¤±è´¥")
        exit(1)

if __name__ == '__main__':
    main() 
