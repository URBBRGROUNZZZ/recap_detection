#!/usr/bin/env python3
"""
ç®€åŒ–çš„è®­ç»ƒå™¨æ¨¡å— - æ”¯æŒç»Ÿä¸€è®­ç»ƒè„šæœ¬å’Œæ–­ç‚¹ç»­è®­
å¢å¼ºç‰ˆï¼šæ”¯æŒWarmup + Cosineå­¦ä¹ ç‡è°ƒåº¦å’ŒFocal Loss
"""

import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
from datetime import datetime
from typing import Dict, Any, Optional
from tqdm import tqdm
import logging
import math

class FocalLoss(nn.Module):
    """
    æ”¹è¿›çš„Focal Lossï¼Œä¸“é—¨å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
    
    Args:
        alpha (float): ç±»åˆ«æƒé‡å¹³è¡¡å‚æ•° (0,1)ï¼Œç»™å°‘æ•°ç±»æ›´é«˜æƒé‡
        gamma (float): èšç„¦å‚æ•°ï¼Œæ§åˆ¶æ˜“åˆ†æ ·æœ¬çš„æƒé‡è¡°å‡
        reduction (str): æŸå¤±èšåˆæ–¹å¼
    """
    def __init__(self, alpha=0.65, gamma=2.0, reduction='mean', class_weights: Optional[tuple] = None):
        super(FocalLoss, self).__init__()
        self.gamma = gamma
        self.reduction = reduction
        # æ”¯æŒåŒæ—¶æŒ‡å®šæ­£è´Ÿç±»alpha
        if isinstance(alpha, (list, tuple)):
            if len(alpha) != 2:
                raise ValueError("FocalLoss alphaä½œä¸ºåˆ—è¡¨/å…ƒç»„æ—¶éœ€è¦æä¾›ä¸¤ä¸ªå€¼: (negative_alpha, positive_alpha)")
            self.alpha_negative = float(alpha[0])
            self.alpha_positive = float(alpha[1])
        else:
            self.alpha_positive = float(alpha)
            self.alpha_negative = 1.0 - self.alpha_positive

        if class_weights is not None:
            if len(class_weights) != 2:
                raise ValueError("class_weightséœ€è¦ä¸¤ä¸ªå€¼ï¼Œå¯¹åº”(raw, recap)")
            self.class_weights = (float(class_weights[0]), float(class_weights[1]))
        else:
            self.class_weights = None
        
    def forward(self, inputs, targets):
        # ç¡®ä¿è¾“å…¥æ˜¯äºŒåˆ†ç±»logits
        if inputs.size(1) != 2:
            raise ValueError("FocalLossæœŸæœ›äºŒåˆ†ç±»è¾“å…¥ï¼Œä½†å¾—åˆ°{}ä¸ªç±»åˆ«".format(inputs.size(1)))
        
        # è®¡ç®—sigmoidæ¦‚ç‡
        probs = torch.sigmoid(inputs[:, 1])  # å–æ­£ç±»çš„æ¦‚ç‡
        
        # è½¬æ¢ä¸ºäºŒåˆ†ç±»æ ‡ç­¾
        targets = targets.float()
        
        # è®¡ç®—focal loss
        pt = torch.where(targets == 1, probs, 1 - probs)
        alpha_pos = torch.tensor(self.alpha_positive, dtype=inputs.dtype, device=inputs.device)
        alpha_neg = torch.tensor(self.alpha_negative, dtype=inputs.dtype, device=inputs.device)
        alpha_t = torch.where(targets == 1, alpha_pos, alpha_neg)
        
        # Focal Losså…¬å¼: -Î±_t * (1-pt)^Î³ * log(pt)
        focal_loss = -alpha_t * torch.pow(1 - pt, self.gamma) * torch.log(pt + 1e-7)

        if self.class_weights is not None:
            weight_tensor = torch.tensor(self.class_weights, dtype=inputs.dtype, device=inputs.device)
            sample_weights = torch.where(targets == 1, weight_tensor[1], weight_tensor[0])
            focal_loss = focal_loss * sample_weights
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

class WarmupCosineScheduler:
    """Warmup + Cosine Annealing å­¦ä¹ ç‡è°ƒåº¦å™¨"""
    
    def __init__(self, optimizer, warmup_epochs, total_epochs, base_lr, min_lr=1e-6):
        self.optimizer = optimizer
        self.warmup_epochs = warmup_epochs
        self.total_epochs = total_epochs
        self.base_lr = base_lr
        self.min_lr = min_lr
        self.current_epoch = 0
        
    def step(self):
        """æ›´æ–°å­¦ä¹ ç‡"""
        if self.current_epoch < self.warmup_epochs:
            # Warmupé˜¶æ®µï¼šçº¿æ€§å¢é•¿
            lr = self.base_lr * (self.current_epoch + 1) / self.warmup_epochs
        else:
            # Cosine Annealingé˜¶æ®µ
            progress = (self.current_epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)
            lr = self.min_lr + 0.5 * (self.base_lr - self.min_lr) * (1 + math.cos(math.pi * progress))
        
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr
        
        self.current_epoch += 1
        return lr

class Trainer:
    """ç®€åŒ–çš„æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, model, train_loader, val_loader, device, lr=0.001, 
                 accumulation_steps=1, save_dir="checkpoints", warmup_epochs=1,
                 use_focal_loss=False, focal_alpha=0.65, focal_gamma=2.0,
                 primary_metric: str = 'accuracy', positive_label: int = 1,
                 class_loss_weights: Optional[tuple] = None):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.save_dir = save_dir
        self.accumulation_steps = accumulation_steps
        self.warmup_epochs = warmup_epochs
        self.use_focal_loss = use_focal_loss
        self.primary_metric = primary_metric.lower()
        self.positive_label = positive_label
        self.class_loss_weights = class_loss_weights
        if self.primary_metric not in {'accuracy', 'recall'}:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¸»è¦æŒ‡æ ‡: {primary_metric}")
        
        # è®¾ç½®æŸå¤±å‡½æ•°
        if use_focal_loss:
            self.criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, class_weights=class_loss_weights)
            self.logger = logging.getLogger(__name__)
            alpha_repr = focal_alpha if not isinstance(focal_alpha, (list, tuple)) else f"neg={focal_alpha[0]}, pos={focal_alpha[1]}"
            self.logger.info(f"ğŸ¯ ä½¿ç”¨Focal Loss: Î±={alpha_repr}, Î³={focal_gamma}")
        else:
            weight_tensor = None
            if class_loss_weights is not None:
                weight_tensor = torch.tensor(class_loss_weights, dtype=torch.float32, device=self.device)
            self.criterion = nn.CrossEntropyLoss(weight=weight_tensor)
            self.logger = logging.getLogger(__name__)
            if class_loss_weights is not None:
                self.logger.info(f"ğŸ“Š ä½¿ç”¨åŠ æƒCrossEntropy Loss: weights={class_loss_weights}")
            else:
                self.logger.info("ğŸ“Š ä½¿ç”¨CrossEntropy Loss")
        self.logger.info(f"ğŸ“Œ ä¸»è¦ä¼˜åŒ–æŒ‡æ ‡: {self.primary_metric}")
        
        # è®¾ç½®ä¼˜åŒ–å™¨ - ä½¿ç”¨AdamWå’Œæƒé‡è¡°å‡
        self.optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆåœ¨trainæ–¹æ³•ä¸­åˆå§‹åŒ–ï¼‰
        self.scheduler = None
        
        # è®­ç»ƒå†å²
        self.history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': [],
            'val_recall': [],
            'learning_rates': []
        }
        
        self.best_val_acc = 0.0
        self.best_val_recall = 0.0
        self.best_val_metric = 0.0
        self.start_epoch = 0  # æ·»åŠ èµ·å§‹epoch
        
        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        os.makedirs(save_dir, exist_ok=True)
    
    def set_resume_state(self, checkpoint: Dict, start_epoch: int, best_val_acc: float,
                         override_primary_metric: Optional[str] = None):
        """è®¾ç½®ä»checkpointæ¢å¤çš„çŠ¶æ€"""
        self.start_epoch = start_epoch
        self.best_val_acc = best_val_acc
        self.best_val_metric = checkpoint.get('best_val_metric', best_val_acc)
        self.best_val_recall = checkpoint.get('best_val_recall', checkpoint.get('best_val_acc', 0.0))
        
        # æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€
        if 'optimizer_state_dict' in checkpoint:
            try:
                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                self.logger.info("âœ… æˆåŠŸæ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€")
            except Exception as e:
                self.logger.warning(f"âš ï¸ æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€å¤±è´¥: {e}")
        
        # æ¢å¤è®­ç»ƒå†å²
        if 'history' in checkpoint:
            try:
                self.history = checkpoint['history']
                self.history.setdefault('val_recall', [])
                self.logger.info("âœ… æˆåŠŸæ¢å¤è®­ç»ƒå†å²")
            except Exception as e:
                self.logger.warning(f"âš ï¸ æ¢å¤è®­ç»ƒå†å²å¤±è´¥: {e}")
        if override_primary_metric:
            override_primary_metric = override_primary_metric.lower()
            if override_primary_metric in {'accuracy', 'recall'}:
                self.primary_metric = override_primary_metric
                if override_primary_metric == 'accuracy':
                    self.best_val_metric = self.best_val_acc
                else:
                    self.best_val_metric = self.best_val_recall
                self.logger.info(f"ğŸ“Œ è¦†ç›–ä¸»è¦æŒ‡æ ‡ä¸º: {self.primary_metric}")
            else:
                self.logger.warning(f"âš ï¸ æœªçŸ¥ä¸»è¦æŒ‡æ ‡ {override_primary_metric}ï¼Œä¿æŒåŸå€¼ {self.primary_metric}")
        elif 'primary_metric' in checkpoint:
            self.primary_metric = str(checkpoint['primary_metric']).lower()
            if self.primary_metric not in {'accuracy', 'recall'}:
                self.primary_metric = 'accuracy'
            self.logger.info(f"ğŸ“Œ ä»checkpointæ¢å¤ä¸»è¦æŒ‡æ ‡: {self.primary_metric}")
            if self.primary_metric == 'accuracy':
                self.best_val_metric = self.best_val_acc
            else:
                self.best_val_metric = self.best_val_recall
        
        self.logger.info(f"ğŸ”„ æ¢å¤çŠ¶æ€: epoch={start_epoch}, best_acc={best_val_acc:.4f}, best_metric={self.best_val_metric:.4f}")
    
    def train_epoch(self, epoch: int):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        
        # è®¡ç®—å®é™…çš„epochæ•°ï¼ˆè€ƒè™‘ä»checkpointæ¢å¤çš„æƒ…å†µï¼‰
        actual_epoch = self.start_epoch + epoch + 1
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = tqdm(
            self.train_loader, 
            desc=f"Epoch {actual_epoch}",
            leave=False
        )
        
        self.optimizer.zero_grad()
        
        for batch_idx, (data, target) in enumerate(progress_bar):
            data, target = data.to(self.device), target.to(self.device)
            
            # å‰å‘ä¼ æ’­
            output = self.model(data)
            loss = self.criterion(output, target)
            
            # æ¢¯åº¦ç´¯ç§¯
            loss = loss / self.accumulation_steps
            loss.backward()
            
            # æ›´æ–°å‚æ•°
            if (batch_idx + 1) % self.accumulation_steps == 0:
                self.optimizer.step()
                self.optimizer.zero_grad()
            
            # ç»Ÿè®¡
            running_loss += loss.item() * self.accumulation_steps
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
            
            # æ›´æ–°è¿›åº¦æ¡
            current_acc = 100.0 * correct / total
            current_lr = self.optimizer.param_groups[0]['lr']
            progress_bar.set_postfix({
                'Loss': f'{running_loss/(batch_idx+1):.4f}',
                'Acc': f'{current_acc:.2f}%',
                'LR': f'{current_lr:.6f}'
            })
        
        # å¦‚æœæœ€åä¸€æ‰¹æ¬¡æ²¡æœ‰è¾¾åˆ°ç´¯ç§¯æ­¥æ•°ï¼Œä¹Ÿè¦æ›´æ–°å‚æ•°
        if len(self.train_loader) % self.accumulation_steps != 0:
            self.optimizer.step()
            self.optimizer.zero_grad()
        
        epoch_loss = running_loss / len(self.train_loader)
        epoch_acc = 100.0 * correct / total
        
        return epoch_loss, epoch_acc
    
    def validate(self):
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        all_targets = []
        all_preds = []
        
        with torch.no_grad():
            progress_bar = tqdm(
                self.val_loader, 
                desc="Validation",
                leave=False
            )
            
            for batch_idx, (data, target) in enumerate(progress_bar):
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                loss = self.criterion(output, target)
                
                val_loss += loss.item()
                _, predicted = torch.max(output.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()
                all_targets.extend(target.cpu().tolist())
                all_preds.extend(predicted.cpu().tolist())
                
                # æ›´æ–°è¿›åº¦æ¡
                current_acc = 100.0 * correct / total
                progress_bar.set_postfix({
                    'Loss': f'{val_loss/(batch_idx+1):.4f}',
                    'Acc': f'{current_acc:.2f}%'
                })
        
        epoch_loss = val_loss / len(self.val_loader)
        epoch_acc = 100.0 * correct / total
        positive_label = self.positive_label
        tp = sum(1 for pred, target in zip(all_preds, all_targets) if pred == positive_label and target == positive_label)
        fn = sum(1 for pred, target in zip(all_preds, all_targets) if pred != positive_label and target == positive_label)
        fp = sum(1 for pred, target in zip(all_preds, all_targets) if pred == positive_label and target != positive_label)
        tn = sum(1 for pred, target in zip(all_preds, all_targets) if pred != positive_label and target != positive_label)
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        metrics = {
            'recall': recall,
            'precision': precision,
            'tp': tp,
            'fn': fn,
            'fp': fp,
            'tn': tn
        }
        
        return epoch_loss, epoch_acc, metrics
    
    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        # è®¡ç®—å®é™…çš„epochæ•°
        actual_epoch = self.start_epoch + epoch
        
        checkpoint = {
            'epoch': actual_epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.current_epoch if self.scheduler else 0,
            'best_val_acc': self.best_val_acc,
            'best_val_recall': self.best_val_recall,
            'best_val_metric': self.best_val_metric,
            'primary_metric': self.primary_metric,
            'history': self.history
        }
        
        # ä¿å­˜æ¯ä¸ªepochçš„æ£€æŸ¥ç‚¹
        checkpoint_path = os.path.join(self.save_dir, f'checkpoint_epoch_{actual_epoch + 1}.pth')
        torch.save(checkpoint, checkpoint_path)
        
        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œé¢å¤–ä¿å­˜ä¸€ä»½
        if is_best:
            best_path = os.path.join(self.save_dir, 'best_model.pth')
            torch.save(checkpoint, best_path)
            self.logger.info(f"ğŸ’¾ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}")
    
    def save_history(self):
        """ä¿å­˜è®­ç»ƒå†å²"""
        history_path = os.path.join(self.save_dir, 'training_history.json')
        
        # æ·»åŠ ä¸€äº›å…ƒæ•°æ®
        full_history = {
            'training_history': self.history,
            'best_validation_accuracy': self.best_val_acc,
            'best_recap_recall': self.best_val_recall,
            'best_primary_metric': self.best_val_metric,
            'primary_metric': self.primary_metric,
            'total_epochs': len(self.history['train_loss']) + self.start_epoch,
            'resumed_from_epoch': self.start_epoch,
            'final_train_acc': self.history['train_acc'][-1] if self.history['train_acc'] else 0,
            'final_val_acc': self.history['val_acc'][-1] if self.history['val_acc'] else 0,
            'final_val_recall': self.history['val_recall'][-1] if self.history['val_recall'] else 0,
            'training_config': {
                'warmup_epochs': self.warmup_epochs,
                'optimizer': 'AdamW',
                'weight_decay': 0.01,
                'scheduler': 'WarmupCosine'
            },
            'saved_at': datetime.now().isoformat()
        }
        
        with open(history_path, 'w', encoding='utf-8') as f:
            json.dump(full_history, f, indent=2, ensure_ascii=False)
    
    def train(self, epochs: int):
        """å®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹"""
        total_epochs = self.start_epoch + epochs
        self.logger.info(f"å¼€å§‹è®­ç»ƒ {epochs} ä¸ªepochs (æ€»è®¡: {total_epochs} epochs)")
        
        # åˆå§‹åŒ–å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = WarmupCosineScheduler(
            self.optimizer, 
            self.warmup_epochs, 
            total_epochs, 
            self.optimizer.param_groups[0]['lr']
        )
        
        # è®¾ç½®è°ƒåº¦å™¨çš„å½“å‰epoch
        for _ in range(self.start_epoch):
            self.scheduler.step()
        
        if self.start_epoch > 0:
            self.logger.info(f"ä»epoch {self.start_epoch} ç»§ç»­è®­ç»ƒ")
        
        self.logger.info(f"ğŸ”¥ ä½¿ç”¨Warmup+Cosineå­¦ä¹ ç‡è°ƒåº¦ (é¢„çƒ­: {self.warmup_epochs} epochs)")
        self.logger.info(f"âš¡ ä½¿ç”¨AdamWä¼˜åŒ–å™¨ + æƒé‡è¡°å‡")
        
        for epoch in range(epochs):
            actual_epoch = self.start_epoch + epoch + 1
            self.logger.info(f"--- Epoch {actual_epoch}/{total_epochs} ---")
            
            # æ›´æ–°å­¦ä¹ ç‡
            current_lr = self.scheduler.step()
            self.logger.info(f"å­¦ä¹ ç‡: {current_lr:.6f}")
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss, train_acc = self.train_epoch(epoch)
            
            # éªŒè¯
            val_loss, val_acc, val_metrics = self.validate()
            val_recall = val_metrics.get('recall', 0.0) * 100.0
            
            # è®°å½•å†å²
            self.history['train_loss'].append(train_loss)
            self.history['train_acc'].append(train_acc)
            self.history['val_loss'].append(val_loss)
            self.history['val_acc'].append(val_acc)
            self.history['val_recall'].append(val_recall)
            self.history['learning_rates'].append(current_lr)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
            if val_acc > self.best_val_acc:
                self.best_val_acc = val_acc
            if val_recall > self.best_val_recall:
                self.best_val_recall = val_recall
            
            metric_value = val_acc if self.primary_metric == 'accuracy' else val_recall
            is_best = metric_value > self.best_val_metric
            if is_best:
                self.best_val_metric = metric_value
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            self.save_checkpoint(epoch, is_best)
            
            # è¾“å‡ºç»“æœ
            self.logger.info(f"è®­ç»ƒ - æŸå¤±: {train_loss:.4f}, å‡†ç¡®ç‡: {train_acc:.2f}%")
            self.logger.info(f"éªŒè¯ - æŸå¤±: {val_loss:.4f}, å‡†ç¡®ç‡: {val_acc:.2f}%, Recapå¬å›ç‡: {val_recall:.2f}%")
            self.logger.info(f"ğŸ“Œ å½“å‰ä¸»è¦æŒ‡æ ‡({self.primary_metric}): {metric_value:.2f}")
            if is_best:
                self.logger.info("ğŸ‰ ä¸»è¦æŒ‡æ ‡å–å¾—æ–°é«˜!")
            self.logger.info("")
        
        # ä¿å­˜è®­ç»ƒå†å²
        self.save_history()
        
        self.logger.info("è®­ç»ƒå®Œæˆ!")
        self.logger.info(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_acc:.2f}%")
        self.logger.info(f"æœ€ä½³Recapå¬å›ç‡: {self.best_val_recall:.2f}%")
        self.logger.info(f"ä¸»è¦æŒ‡æ ‡({self.primary_metric})æœ€ä½³å€¼: {self.best_val_metric:.2f}")
        
        return self.history
