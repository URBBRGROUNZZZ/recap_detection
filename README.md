# ðŸ“± æ‰‹æœºç¿»æ‹æ£€æµ‹é¡¹ç›®

è¿™ä¸ªé¡¹ç›®ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡åž‹æ£€æµ‹æ‰‹æœºå±å¹•å›¾ç‰‡ä¸­çš„ç¿»æ‹æ•ˆåº”ï¼Œæ”¯æŒResNet152ã€ViT-Baseã€ViT-Largeç­‰å¤šç§æ¨¡åž‹æž¶æž„ï¼Œå¹¶åˆ›æ–°æ€§åœ°å¼•å…¥Siameseç½‘ç»œæž¶æž„ï¼Œæ˜¾è‘—æå‡æ¨¡åž‹æ€§èƒ½ã€‚

## ðŸŽ¯ é¡¹ç›®ç‰¹ç‚¹

- âœ… **å¤šæ¨¡åž‹æ”¯æŒ** - ResNet152ã€ViT-Baseã€ViT-Largeã€MobileNet-V3-Large
- âœ… **Siameseç½‘ç»œæž¶æž„** - å¯¹æ¯”å­¦ä¹ æ˜¾è‘—æå‡å‡†ç¡®çŽ‡ï¼ˆ91% â†’ 96%+ï¼‰
- âœ… **å¤§æ•°æ®é›†è®­ç»ƒ** - 55K+å¼ é«˜è´¨é‡å›¾ç‰‡
- âœ… **ç»Ÿä¸€è®­ç»ƒè„šæœ¬** - æ”¯æŒå¤šæ¨¡åž‹ã€è‡ªå®šä¹‰epochs
- âœ… **ç»Ÿä¸€æŽ¨ç†è„šæœ¬** - å•å›¾ã€æ‰¹é‡ã€æ··æ·†çŸ©é˜µã€æ¨¡åž‹å¯¹æ¯”
- âœ… **è‡ªåŠ¨åŒ–æµç¨‹** - æ•°æ®éªŒè¯ã€é”™è¯¯ä¿å­˜ã€æ€§èƒ½åˆ†æž
- âœ… **é«˜æ€§èƒ½è¡¨çŽ°** - ViT-Large-Siameseè¾¾åˆ°99.91%å‡†ç¡®çŽ‡

## ðŸ“ é¡¹ç›®ç»“æž„

```
phonerecap/
â”œâ”€â”€ image/
â”‚   â”œâ”€â”€ raw/                    # Rawå›¾ç‰‡æ–‡ä»¶å¤¹ (486å¼ )
â”‚   â”œâ”€â”€ recap/                  # Recapå›¾ç‰‡æ–‡ä»¶å¤¹ (455å¼ )
â”‚   â”œâ”€â”€ raw_compressed/         # åŽ‹ç¼©åŽçš„Rawå›¾ç‰‡
â”‚   â””â”€â”€ recap_compressed/       # åŽ‹ç¼©åŽçš„Recapå›¾ç‰‡
â”œâ”€â”€ checkpoints/                # è®­ç»ƒå¥½çš„æ¨¡åž‹
â”‚   â”œâ”€â”€ vit_base_xxx_optimized/ # ViT-Baseä¼˜åŒ–æ¨¡åž‹
â”‚   â”œâ”€â”€ vit_large_xxx_optimized/# ViT-Largeä¼˜åŒ–æ¨¡åž‹
â”‚   â”œâ”€â”€ mobilenet_siamese/      # MobileNet-Siameseæ¨¡åž‹
â”‚   â””â”€â”€ vit_large_siamese_full/ # ViT-Large-Siameseæ¨¡åž‹
â”œâ”€â”€ train_unified.py            # ç»Ÿä¸€è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference_unified.py        # ç»Ÿä¸€æŽ¨ç†è„šæœ¬
â”œâ”€â”€ trainer.py                  # è®­ç»ƒå™¨æ¨¡å—
â”œâ”€â”€ model.py                    # æ¨¡åž‹æž¶æž„å®šä¹‰
â”œâ”€â”€ dataset_simple.py           # æ•°æ®é›†å¤„ç†
â””â”€â”€ README.md                   # é¡¹ç›®è¯´æ˜Žæ–‡æ¡£
```

## ðŸš€ å¿«é€Ÿå¼€å§‹

### 1. çŽ¯å¢ƒå‡†å¤‡

```bash
# åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ
python -m venv .venv

# æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ
source .venv/bin/activate  # macOS/Linux
# æˆ– .venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. éªŒè¯å®‰è£…

```bash
python -c "import torch, torchvision, timm, PIL; print('âœ… æ‰€æœ‰ä¾èµ–å®‰è£…æˆåŠŸ')"
```

### 3. å¿«é€Ÿè®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤CursorQå¤§æ•°æ®é›†è®­ç»ƒViT-Baseæ¨¡åž‹
python script/train_unified.py --models vit_base --epochs 4

# è®­ç»ƒå¤šä¸ªæ¨¡åž‹
python script/train_unified.py --models resnet152 vit_base vit_large --epochs 6 4 4

# è®­ç»ƒSiameseç½‘ç»œï¼ˆæŽ¨è - æ€§èƒ½æœ€ä½³ï¼‰
```

### 4. å¿«é€ŸæŽ¨ç†

```bash
# å•å›¾åˆ†ç±»
python script/inference_unified.py --mode single --model vit_large --image test.jpg

# æ–‡ä»¶å¤¹æ‰¹é‡åˆ†ç±»
python script/inference_unified.py --mode folder --model vit_base --folder image/raw --output results/
# è®¡ç®—æ··æ·†çŸ©é˜µï¼ˆæ ‡å‡†æ¨¡åž‹ï¼‰
python script/inference_unified.py --mode confusion --model vit_large --raw_folder image/raw/ --recap_folder image/recap/ --save_errors

# è®¡ç®—æ··æ·†çŸ©é˜µï¼ˆSiameseæ¨¡åž‹ - æŽ¨èï¼‰
python script/inference_unified.py --mode confusion --model vit_large_siamese --model_path checkpoints/vit_large_siamese_full/best_vit_large_siamese.pth --raw_folder image/raw --recap_folder image/recap --output results/vit_large_siamese_best
```

## ðŸ”§ çŽ¯å¢ƒè¦æ±‚

### æ ¸å¿ƒä¾èµ–

- **Python 3.8+**
- **PyTorch 1.12+** - æ·±åº¦å­¦ä¹ æ¡†æž¶
- **torchvision** - å›¾åƒå¤„ç†
- **timm** - é¢„è®­ç»ƒæ¨¡åž‹åº“
- **scikit-learn** - æ€§èƒ½è¯„ä¼°
- **matplotlib & seaborn** - å¯è§†åŒ–
- **PIL** - å›¾åƒå¤„ç†
- **tqdm** - è¿›åº¦æ¡

### å®‰è£…æ–¹å¼

```bash
# å®Œæ•´å®‰è£…ï¼ˆæŽ¨èï¼‰
pip install -r requirements.txt

# æœ€å°å®‰è£…ï¼ˆä»…æŽ¨ç†ï¼‰
pip install -r requirements-api.txt
```

## ðŸŽ“ è®­ç»ƒæŒ‡å—

### åŸºæœ¬ç”¨æ³•

#### 1. ä½¿ç”¨é»˜è®¤æ•°æ®é›†

```bash
# è®­ç»ƒå•ä¸ªæ¨¡åž‹ï¼ˆä½¿ç”¨CursorQæ•°æ®é›†ï¼š55K+å¼ å›¾ç‰‡ï¼‰
python script/train_unified.py --models vit_base --epochs 4

# è®­ç»ƒå¤šä¸ªæ¨¡åž‹ï¼Œä¸åŒepochs
python script/train_unified.py --models resnet152 vit_base vit_large --epochs 6 4 4
```

#### 2. è‡ªå®šä¹‰æ•°æ®é›†

```bash
# æŒ‡å®šraw/recapæ–‡ä»¶å¤¹
python script/train_unified.py --models vit_base --epochs 4 --raw image/raw image/raw_cut --recap image/recap image/recap_cut

# ä½¿ç”¨positive/negativeæ¨¡å¼ï¼ˆé€šç”¨äºŒåˆ†ç±»ï¼‰
python script/train_unified.py --models vit_base --epochs 4 --positive positive_samples --negative negative_samples
```

#### 3. é«˜çº§é…ç½®

```bash
# è‡ªå®šä¹‰éªŒè¯é›†æ¯”ä¾‹å’Œä¿å­˜ç›®å½•
python script/train_unified.py \
    --models vit_base vit_large \
    --epochs 5 6 \
    --validation-split 0.15 \
    --save-dir my_models
```

### æ”¯æŒçš„æ¨¡åž‹

| æ¨¡åž‹ | æ‰¹æ¬¡å¤§å° | å­¦ä¹ çŽ‡ | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° | æè¿° |
|------|----------|--------|--------------|------|
| resnet152 | 8 | 0.001 | 3 | ResNet152 CNNæ¨¡åž‹ |
| vit_base | 6 | 0.0001 | 4 | ViT-Base Transformeræ¨¡åž‹ |
| vit_large | 4 | 0.0001 | 6 | ViT-Large Transformeræ¨¡åž‹ |
| mobilenet_v3_large | 12 | 0.001 | 2 | MobileNet-V3-Largeè½»é‡çº§æ¨¡åž‹ |
| mobilenet_v3_large_siamese | 16 | 0.002 | 2 | MobileNet-Siameseå¯¹æ¯”å­¦ä¹ æ¨¡åž‹ |
| vit_large_siamese | 8 | 0.0001 | 4 | ViT-Large-Siameseå¯¹æ¯”å­¦ä¹ æ¨¡åž‹ï¼ˆæŽ¨èï¼‰|
| efficientnet_b7 | 2 | 0.0001 | 12 | EfficientNet-B7 é«˜ç²¾åº¦æ¨¡åž‹ |
| efficientnet_v2_s | 10 | 0.0005 | 3 | EfficientNetV2-S è½»é‡é«˜ç²¾åº¦æ¨¡åž‹ |
| efficientnet_v2_lite0 | 16 | 0.001 | 2 | EfficientNetV2-T è½»é‡æ¨¡åž‹ï¼ˆtimmå®žçŽ°ï¼‰ |

> å¦‚æžœä¸šåŠ¡éœ€è¦â€œå®å¯è¯¯åˆ¤åŽŸå›¾ï¼Œä¹Ÿä¸èƒ½æ¼åˆ¤ç¿»æ‹â€ï¼Œå¯ä»¥åœ¨è®­ç»ƒæ—¶é™„åŠ  `--recap-priority`ã€‚è¯¥é€‰é¡¹ä¼šå¯ç”¨Focal LossåŠ æƒã€è‡ªåŠ¨æé«˜ç¿»æ‹è¿‡é‡‡æ ·æ¯”ä¾‹ï¼Œå¹¶å°†æœ€ä½³æ¨¡åž‹çš„è¯„ä¼°æŒ‡æ ‡åˆ‡æ¢ä¸ºç¿»æ‹å¬å›žçŽ‡ã€‚éœ€è¦æ›´å¤§åŠ›åº¦æ—¶ï¼Œå¯é…åˆ `--recap-oversample 2.0` ä»¥ä¸Šä»¥åŠ `--primary-metric recall` åšè¿›ä¸€æ­¥è°ƒèŠ‚ã€‚
### é»˜è®¤æ•°æ®é›†

è„šæœ¬é»˜è®¤ä½¿ç”¨CursorQå¤§åž‹æ•°æ®é›†ï¼ˆ55,315å¼ å›¾ç‰‡ï¼‰ï¼š
- `/Users/karl/Downloads/CursorQ/all_videos_frames_advanced/raw_p` (2,938å¼ )
- `/Users/karl/Downloads/CursorQ/all_videos_frames_advanced/raw_v` (29,679å¼ )
- `/Users/karl/Downloads/CursorQ/all_videos_frames_advanced/recap_p` (1,504å¼ )
- `/Users/karl/Downloads/CursorQ/all_videos_frames_advanced/recap_v` (21,194å¼ )

å¦‚æžœCursorQè·¯å¾„ä¸å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨å½“å‰ç›®å½•çš„ `raw` å’Œ `recap` æ–‡ä»¶å¤¹ã€‚

### è¾“å‡ºæ–‡ä»¶

```
checkpoints/
â”œâ”€â”€ {model}_{timestamp}_unified/
â”‚   â”œâ”€â”€ best_model.pth              # æœ€ä½³æ¨¡åž‹æƒé‡
â”‚   â”œâ”€â”€ checkpoint_epoch_X.pth      # æ¯ä¸ªepochçš„checkpoint
â”‚   â”œâ”€â”€ training_config.json        # è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ training_history.json       # è®­ç»ƒåŽ†å²
â””â”€â”€ logs/
    â””â”€â”€ unified_training_{timestamp}.log  # è®­ç»ƒæ—¥å¿—
```

## ðŸ” æŽ¨ç†æŒ‡å—

### åŠŸèƒ½æ¨¡å¼

#### 1. å•å›¾åˆ†ç±»

å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œåˆ†ç±»é¢„æµ‹ï¼š

```bash
# åŸºæœ¬ç”¨æ³•
python script/inference_unified.py --mode single --model vit_base --image path/to/image.jpg

# ä½¿ç”¨è‡ªå®šä¹‰æ¨¡åž‹
python script/inference_unified.py --mode single --model vit_large --model_path custom/model.pth --image image.jpg
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
ðŸ“Š é¢„æµ‹ç»“æžœ:
å›¾ç‰‡: path/to/image.jpg
ç±»åˆ«: recap
ç½®ä¿¡åº¦: 0.9876
æ¦‚çŽ‡åˆ†å¸ƒ: Raw=0.0124, Recap=0.9876
```

#### 2. æ–‡ä»¶å¤¹åˆ†ç±»

æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡ï¼š

```bash
# åŸºæœ¬ç”¨æ³•
python script/inference_unified.py --mode folder --model vit_base --folder /path/to/images

# ä¿å­˜è¯¦ç»†ç»“æžœ
python script/inference_unified.py --mode folder --model vit_base --folder /path/to/images --output results/
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
ðŸ“Š åˆ†ç±»ç»“æžœç»Ÿè®¡:
  Raw: 245 å¼  (52.3%)
  Recap: 223 å¼  (47.7%)
  æ€»è®¡: 468 å¼ 
```

#### 3. æ··æ·†çŸ©é˜µè®¡ç®—

ä½¿ç”¨ä¸¤ä¸ªæ–‡ä»¶å¤¹ï¼ˆå·²çŸ¥æ ‡ç­¾ï¼‰è®¡ç®—æ¨¡åž‹æ€§èƒ½ï¼š

```bash
# åŸºæœ¬æ··æ·†çŸ©é˜µ
python script/inference_unified.py --mode confusion --model vit_base --raw_folder image/raw/ --recap_folder image/recap/

# ä¿å­˜é”™è¯¯åˆ†ç±»çš„å›¾ç‰‡
python script/inference_unified.py --mode confusion --model vit_large --raw_folder image/raw/ --recap_folder image/recap/ --save_errors --output results/
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
ðŸ“Š æ··æ·†çŸ©é˜µç»“æžœ:
æ€»ä½“å‡†ç¡®çŽ‡: 0.9456 (94.56%)
Rawå‡†ç¡®çŽ‡: 0.9234 (92.34%)
Recapå‡†ç¡®çŽ‡: 0.9678 (96.78%)
é”™è¯¯åˆ†ç±»: 51 å¼ 
  Rawè¯¯åˆ†ä¸ºRecap: 35 å¼ 
  Recapè¯¯åˆ†ä¸ºRaw: 16 å¼ 
```

#### 4. æ¨¡åž‹æ€§èƒ½å¯¹æ¯”

åŒæ—¶æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡åž‹çš„æ€§èƒ½ï¼š

```bash
# å¯¹æ¯”æ‰€æœ‰æ¨¡åž‹
python script/inference_unified.py --mode compare --raw_folder image/raw/ --recap_folder image/recap/ --output comparison/
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
ðŸ“Š æ¨¡åž‹æ€§èƒ½æ¯”è¾ƒ:
  resnet152: 0.8812 (88.12%)
  vit_base: 0.9342 (93.42%)
  vit_large: 0.9456 (94.56%)
```

### é«˜çº§åŠŸèƒ½

#### é”™è¯¯å›¾ç‰‡ä¿å­˜

åœ¨æ··æ·†çŸ©é˜µæ¨¡å¼ä¸‹ä¿å­˜åˆ†ç±»é”™è¯¯çš„å›¾ç‰‡ï¼š

```bash
python script/inference_unified.py --mode confusion --model vit_base --raw_folder raw/ --recap_folder recap/ --save_errors
```

ç”Ÿæˆæ–‡ä»¶å¤¹ç»“æž„ï¼š
```
{model_name}_errors_{timestamp}/
â”œâ”€â”€ raw_misclassified_as_recap/     # Rawè¢«è¯¯åˆ†ç±»ä¸ºRecapçš„å›¾ç‰‡
â”œâ”€â”€ recap_misclassified_as_raw/     # Recapè¢«è¯¯åˆ†ç±»ä¸ºRawçš„å›¾ç‰‡
â””â”€â”€ error_details.json              # é”™è¯¯è¯¦æƒ…æ–‡ä»¶
```

#### è®¾å¤‡é€‰æ‹©

```bash
# è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼ˆé»˜è®¤ï¼‰
python script/inference_unified.py --mode single --model vit_base --image image.jpg --device auto

# å¼ºåˆ¶ä½¿ç”¨CPU
python script/inference_unified.py --mode single --model vit_base --image image.jpg --device cpu

# ä½¿ç”¨GPUï¼ˆå¦‚æžœå¯ç”¨ï¼‰
python script/inference_unified.py --mode single --model vit_base --image image.jpg --device cuda
```

### è¾“å‡ºæ–‡ä»¶

- **æ–‡ä»¶å¤¹åˆ†ç±»**: `folder_results_{model}_{timestamp}.json`
- **æ··æ·†çŸ©é˜µ**: `confusion_matrix_{model}_{timestamp}.json` + `.png`
- **æ¨¡åž‹å¯¹æ¯”**: `model_comparison_{timestamp}.json`
- **é”™è¯¯å›¾ç‰‡**: `{model}_errors_{timestamp}/` æ–‡ä»¶å¤¹

## ðŸ“Š æ€§èƒ½åŸºå‡†

### æ¨¡åž‹æ€§èƒ½å¯¹æ¯”

| æ¨¡åž‹ | æ€»ä½“å‡†ç¡®çŽ‡ | Rawå‡†ç¡®çŽ‡ | Recapå‡†ç¡®çŽ‡ | å‚æ•°é‡ | æŽ¨ç†é€Ÿåº¦ | ç‰¹ç‚¹ |
|------|------------|-----------|-------------|--------|----------|------|
| ResNet152 | 88.88% | 81.80% | 96.47% | 60M | å¿« | CNNåŸºç¡€æ¨¡åž‹ |
| ViT-Base | 93.42% | 87.72% | 99.53% | 86M | ä¸­ç­‰ | Transformerå¹³è¡¡æ¨¡åž‹ |
| ViT-Large | 94.56% | 91.7% | 99.1% | 307M | æ…¢ | å¤§Transformeræ¨¡åž‹ |
| MobileNet-V3-Large | 99.55% | 99.59% | 99.51% | 5.4M | å¾ˆå¿« | è½»é‡çº§æ¨¡åž‹ |
| **MobileNet-Siamese** | **91.07%** | **88.48%** | **93.85%** | **14M** | **å¿«** | **å¯¹æ¯”å­¦ä¹ å¢žå¼º** |
| **ViT-Large-Siamese** | **99.91%** | **99.79%** | **100.0%** | **308M** | **ä¸­ç­‰** | **æœ€ä½³æ€§èƒ½ï¼ˆæŽ¨èï¼‰** |

### æ•°æ®é›†ç»Ÿè®¡

- **æ€»æ•°æ®é‡**: 55,989å¼ å›¾ç‰‡ï¼ˆä½¿ç”¨CursorQæ•°æ®é›†ï¼‰
- **Rawå›¾ç‰‡**: 33,019å¼ 
- **Recapå›¾ç‰‡**: 22,970å¼ 
- **è®­ç»ƒ/éªŒè¯åˆ†å‰²**: 80/20

### æ€§èƒ½å»ºè®®

1. **å‡†ç¡®çŽ‡ä¼˜å…ˆ**: ä½¿ç”¨ViT-Large-Siameseæ¨¡åž‹ï¼ˆ99.91%å‡†ç¡®çŽ‡ï¼‰
2. **é€Ÿåº¦ä¼˜å…ˆ**: ä½¿ç”¨ResNet152æ¨¡åž‹
3. **å¹³è¡¡é€‰æ‹©**: ä½¿ç”¨ViT-Baseæ¨¡åž‹
4. **ç§»åŠ¨ç«¯éƒ¨ç½²**: ä½¿ç”¨MobileNet-V3-Largeæ¨¡åž‹

## ðŸ§  Siameseç½‘ç»œæž¶æž„

### æŠ€æœ¯åŽŸç†

æœ¬é¡¹ç›®åˆ›æ–°æ€§åœ°å°†Siameseå¯¹æ¯”å­¦ä¹ æž¶æž„åº”ç”¨åˆ°æ‰‹æœºç¿»æ‹æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œé€šè¿‡åŒè·¯å¾„ç½‘ç»œå­¦ä¹ å›¾ç‰‡é—´çš„ç›¸ä¼¼æ€§å·®å¼‚ï¼Œæ˜¾è‘—æå‡æ¨¡åž‹æ€§èƒ½ã€‚

### æž¶æž„ä¼˜åŠ¿

**1. å¯¹æ¯”å­¦ä¹ æœºåˆ¶**
```python
# å¯¹æ¯”æŸå¤±å‡½æ•°å¼ºåˆ¶æ¨¡åž‹å­¦ä¹ åˆ¤åˆ«æ€§ç‰¹å¾
contrastive_loss = (1-label_same) * max(0, margin - similarity) + 
                   label_same * max(0, similarity - (1-margin))
```

**2. åŒè·¯å¾„ç‰¹å¾å¢žå¼º**
- ç›¸åŒbackboneä¿è¯ç‰¹å¾ç©ºé—´ä¸€è‡´æ€§
- ç›¸å¯¹å­¦ä¹ ï¼šå­¦ä¹ "raw vs recap"çš„ç›¸å¯¹å·®å¼‚
- æ•°æ®æ•ˆçŽ‡ï¼šæ¯ä¸ªbatchèŽ·å¾—2å€æœ‰æ•ˆè®­ç»ƒæ ·æœ¬

**3. æ€§èƒ½æå‡æ˜¾è‘—**
- ViT-Large: 94.56% â†’ ViT-Large-Siamese: 99.91%ï¼ˆ+5.35%ï¼‰
- MobileNet: 99.55% â†’ MobileNet-Siamese: 91.07%ï¼ˆå¯¹æ¯”å­¦ä¹ åŸºçº¿ï¼‰

### è®­ç»ƒSiameseæ¨¡åž‹

```bash
# MobileNet-Siameseè®­ç»ƒ
    --data_path /Users/karl/Downloads/CursorQ/all_videos_frames_advanced \
    --save_path checkpoints/mobilenet_siamese \
    --max_epoch 4 --batch_size 16 --lr 0.002

# ViT-Large-Siameseè®­ç»ƒï¼ˆæŽ¨èï¼‰
    --data_path /Users/karl/Downloads/CursorQ/all_videos_frames_advanced \
    --save_path checkpoints/vit_large_siamese_full \
    --max_epoch 4 --batch_size 8 --lr 0.0001 --pretrained --alpha 0.5
```

### Siameseæ¨¡åž‹æŽ¨ç†

```bash
# æµ‹è¯•MobileNet-Siamese
python script/inference_unified.py --mode confusion --model mobilenet_v3_large_siamese \
    --model_path checkpoints/mobilenet_siamese/best_mobilenet_v3_large_siamese.pth \
    --raw_folder image/raw --recap_folder image/recap

# æµ‹è¯•ViT-Large-Siameseï¼ˆæœ€ä½³æ€§èƒ½ï¼‰
python script/inference_unified.py --mode confusion --model vit_large_siamese \
    --model_path checkpoints/vit_large_siamese_full/best_vit_large_siamese.pth \
    --raw_folder image/raw --recap_folder image/recap --output results/vit_large_siamese_best
```

## ðŸ”§ æ•…éšœæŽ’é™¤

### å¸¸è§é”™è¯¯

#### 1. æ¨¡åž‹æœªæ‰¾åˆ°
```
é”™è¯¯: æœªæ‰¾åˆ°æ¨¡åž‹ vit_baseï¼Œå¯ç”¨æ¨¡åž‹: ['resnet152']
è§£å†³: æ£€æŸ¥checkpointsç›®å½•ï¼Œç¡®ä¿æ¨¡åž‹æ–‡ä»¶å­˜åœ¨
```

#### 2. æ•°æ®è·¯å¾„é”™è¯¯
```
é”™è¯¯: æ•°æ®è·¯å¾„ä¸å­˜åœ¨: /path/to/folder
è§£å†³: æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨ä¸”åŒ…å«å›¾ç‰‡æ–‡ä»¶
```

#### 3. å†…å­˜ä¸è¶³
```
è§£å†³: ä½¿ç”¨ --device cpu å¼ºåˆ¶ä½¿ç”¨CPUï¼Œæˆ–å¤„ç†è¾ƒå°çš„å›¾ç‰‡æ‰¹æ¬¡
```

#### 4. epochså‚æ•°ä¸åŒ¹é…
```
é”™è¯¯: epochsæ•°é‡å¿…é¡»ä¸Žmodelsæ•°é‡åŒ¹é…
è§£å†³: ç¡®ä¿epochsæ•°é‡ä¸Žmodelsæ•°é‡ä¸€è‡´ï¼Œæˆ–åªæŒ‡å®šä¸€ä¸ªepochsåº”ç”¨åˆ°æ‰€æœ‰æ¨¡åž‹
```

### æ€§èƒ½ä¼˜åŒ–

1. **å¤§æ‰¹é‡å¤„ç†**: ä½¿ç”¨GPUå¯ä»¥æ˜¾è‘—æå‡é€Ÿåº¦
2. **å†…å­˜ä¼˜åŒ–**: å¯¹äºŽå¤§é‡å›¾ç‰‡ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†
3. **å­˜å‚¨ç©ºé—´**: ä¿å­˜é”™è¯¯å›¾ç‰‡éœ€è¦é¢å¤–çš„å­˜å‚¨ç©ºé—´

## ðŸ“– ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´å·¥ä½œæµç¨‹

```bash
# 1. çŽ¯å¢ƒå‡†å¤‡
source .venv/bin/activate
pip install -r requirements.txt

# 2. è®­ç»ƒæ¨¡åž‹
python script/train_unified.py --models vit_base vit_large --epochs 4 4

# 3. è¯„ä¼°æ€§èƒ½
python script/inference_unified.py --mode compare --raw_folder image/raw/ --recap_folder image/recap/ --output evaluation/

# 4. å•å›¾æµ‹è¯•
python script/inference_unified.py --mode single --model vit_large --image test_image.jpg

# 5. æ‰¹é‡åˆ†ç±»
python script/inference_unified.py --mode folder --model vit_large --folder unknown_images/ --output classification_results/
```

### APIä½¿ç”¨ï¼ˆå•å›¾åˆ†ç±»ï¼‰

```python
# å¦‚éœ€APIè°ƒç”¨ï¼Œè¯·å‚è€ƒinference_unified.pyä¸­çš„UnifiedInferenceç±»
from inference_unified import UnifiedInference

# åˆå§‹åŒ–æŽ¨ç†å™¨
inference = UnifiedInference('vit_large', 'checkpoints/vit_large_xxx/best_model.pth')

# å•å›¾é¢„æµ‹
result = inference.predict_single('image.jpg')
print(f"ç±»åˆ«: {result['class']}, ç½®ä¿¡åº¦: {result['confidence']:.4f}")
```

## ðŸ“ æ›´æ–°æ—¥å¿—

### v2.0 (2025-07-17)
- âœ… æ•´åˆæ‰€æœ‰è®­ç»ƒè„šæœ¬ä¸ºç»Ÿä¸€è„šæœ¬
- âœ… æ•´åˆæ‰€æœ‰æŽ¨ç†è„šæœ¬ä¸ºç»Ÿä¸€è„šæœ¬
- âœ… é»˜è®¤ä½¿ç”¨CursorQå¤§æ•°æ®é›†ï¼ˆ55K+å¼ å›¾ç‰‡ï¼‰
- âœ… æ”¯æŒé”™è¯¯å›¾ç‰‡è‡ªåŠ¨ä¿å­˜
- âœ… ä¼˜åŒ–å†…å­˜ç®¡ç†å’Œæ€§èƒ½

### v1.0 (2025-07-01)
- âœ… æ”¯æŒå¤šç§æ¨¡åž‹æž¶æž„
- âœ… åŸºç¡€è®­ç»ƒå’ŒæŽ¨ç†åŠŸèƒ½
- âœ… æ€§èƒ½è¯„ä¼°å’Œå¯è§†åŒ–

---

## ðŸ¤ è´¡çŒ®

å¦‚æžœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿Žæäº¤Issueæˆ–Pull Requestã€‚

## ðŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ï¼Œè¯¦è§LICENSEæ–‡ä»¶ã€‚

---

ðŸŽ‰ **å¼€å§‹ä½“éªŒä¸“ä¸šçš„æ‰‹æœºç¿»æ‹æ£€æµ‹ç³»ç»Ÿï¼** 
=======
# recap_detection
recap_detection
>>>>>>> origin/main
